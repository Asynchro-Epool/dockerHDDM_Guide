lpds <- parallel::mclapply(X = seq_len(N), mc.cores = cores, FUN = lpd_i, llfun, data, draws)
} else {
cl <- makePSOCKcluster(cores)
on.exit(stopCluster(cl))
lpds <- parLapply(cl, X = seq_len(N), fun = lpd_i, llfun, data, draws)
}
}
unlist(lpds)
}
elpd_loo_approx <- compute_lpds(N, data, point_est, llfun_logistic, cores=1)
draws <- parameter_draws_1  # 4000 * 3
data <- stan_df_1
llfun <- llfun_logistic
N <- dim(data)[1]
estimator <- "diff_srs"
loo_approximation = 'plpd'
observations <- 100
##  elpd_loo_approx <- elpd_loo_approximation ()...
# draws <- .thin_draws(draws, loo_approximation_draws)
# here we define compute_lpds and related function (lpd_i, logMeanExp) so that we can
# reproduce the elpd_loo_approximation part, which returns a vector of lpds
# https://github.com/stan-dev/loo/blob/e197aa7c5ac56881ad67dae3f90479af96d83c0a/R/helpers.R#L13
logMeanExp <- function(x) {
logS <- log(length(x))
matrixStats::logSumExp(x) - logS
}
lpd_i <- function(i, llfun, data, draws) {
ll_i <- llfun(data_i = data[i,, drop=FALSE], draws = draws)
ll_i <- as.vector(ll_i)
lpd_i <- logMeanExp(ll_i)
lpd_i
}
compute_lpds <- function(N, data, draws, llfun, cores) {
if (cores == 1) {
lpds <- lapply(X = seq_len(N), FUN = lpd_i, llfun, data, draws)
} else {
if (.Platform$OS.type != "windows") {
lpds <- parallel::mclapply(X = seq_len(N), mc.cores = cores, FUN = lpd_i, llfun, data, draws)
} else {
cl <- makePSOCKcluster(cores)
on.exit(stopCluster(cl))
lpds <- parLapply(cl, X = seq_len(N), fun = lpd_i, llfun, data, draws)
}
}
unlist(lpds)
}
elpd_loo_approx <- compute_lpds(N, data, point_est, llfun_logistic, cores=1)
subsample_idxs <- function(estimator, elpd_loo_approximation, observations) {
if (estimator == "hh_pps") {
pi_values <- pps_elpd_loo_approximation_to_pis(elpd_loo_approximation)
idxs_df <- pps_sample(observations, pis = pi_values)
}
if (estimator == "diff_srs" | estimator == "srs") {
if (observations > length(elpd_loo_approximation)) {
stop("'observations' is larger than the total sample size in 'data'.", call. = FALSE)
}
idx <- 1:length(elpd_loo_approximation)
# order function here is not the real ranking of data, but how to get those data so that the new a[order(a)] is ascending.
idx_m <- idx[order(stats::runif(length(elpd_loo_approximation)))][1:observations]
idx_m <- idx_m[order(idx_m)]
idxs_df <- data.frame(idx=as.integer(idx_m), m_i=1L)
}
# assert_subsample_idxs(x = idxs_df)
idxs_df
}
observations <- 100
idxs <- subsample_idxs(
estimator = "diff_srs", # here the default is simple random sampling (srs), i.e. randomly sub-sample
elpd_loo_approximation = elpd_loo_approx,
observations = observations)
elpd_loo_approximation <- elpd_loo_approx
# understand order()
set.seed(123)
tmp2 <- stats::runif(10)
order(tmp2)
tmp2[order(tmp2)]
data_subsample <- data[idxs$idx,, drop = FALSE]
if (length(r_eff) > 1) {
r_eff <- r_eff[idxs$idx]
}
loo_obj <- loo.function(
x = llfun_logistic,
data = data_subsample,
draws = draws,
r_eff = r_eff,
#save_psis = save_psis,
#cores = cores
)
loo_approximation_choices <- function(api = TRUE) {
lac <- c("plpd", "lpd", "waic", "waic_grad_marginal", "waic_grad", "waic_hess", "tis", "sis", "none")
if (!api) lac <- c(lac, "psis")
lac
}
estimator_choices <- function() {
c("hh_pps", "diff_srs", "srs")
}
psis_loo_ss_object <- function(x,
idxs,
elpd_loo_approx,
loo_approximation, loo_approximation_draws,
estimator,
.llfun, .llgrad, .llhess,
data_dim, ndraws) {
# Assertions
checkmate::assert_class(x, "psis_loo")
# assert_subsample_idxs(idxs)
checkmate::assert_numeric(elpd_loo_approx, any.missing = FALSE)
checkmate::assert_choice(loo_approximation, loo_approximation_choices())
checkmate::assert_int(loo_approximation_draws, null.ok = TRUE)
checkmate::assert_choice(estimator, estimator_choices())
checkmate::assert_function(.llfun, args = c("data_i", "draws"), ordered = TRUE)
checkmate::assert_function(.llgrad, args = c("data_i", "draws"), ordered = TRUE, null.ok = TRUE)
checkmate::assert_function(.llhess, args = c("data_i", "draws"), ordered = TRUE, null.ok = TRUE)
checkmate::assert_integer(data_dim, len = 2, lower = 1, any.missing = FALSE)
checkmate::assert_int(ndraws, lower = 1)
# Construct object
class(x) <- c("psis_loo_ss", class(x))
x$pointwise <- add_subsampling_vars_to_pointwise(pointwise = x$pointwise, idxs, elpd_loo_approx)
x$estimates <- cbind(x$estimates, matrix(0, nrow = nrow(x$estimates)))
colnames(x$estimates)[ncol(x$estimates)] <- "subsampling SE"
x$loo_subsampling <- list()
x$loo_subsampling$elpd_loo_approx <- elpd_loo_approx
x$loo_subsampling$loo_approximation <- loo_approximation
x$loo_subsampling["loo_approximation_draws"] <- list(loo_approximation_draws)
x$loo_subsampling$estimator <- estimator
x$loo_subsampling$.llfun <- .llfun
x$loo_subsampling[".llgrad"] <- list(.llgrad)
x$loo_subsampling[".llhess"] <- list(.llhess)
x$loo_subsampling$data_dim <- data_dim
x$loo_subsampling$ndraws <- ndraws
# Compute estimates
if (estimator == "hh_pps") {
x <- loo_subsample_estimation_hh(x)
} else if (estimator == "diff_srs") {
x <- loo_subsample_estimation_diff_srs(x)
} else if (estimator == "srs") {
x <- loo_subsample_estimation_srs(x)
} else {
stop("No correct estimator used.")
}
assert_psis_loo_ss(x)
x
}
.ndraws <- function(x) {
UseMethod(".ndraws")
}
.ndraws.matrix <- function(x) {
nrow(x)
}
.ndraws.default <- function(x) {
stop(".ndraws() has not been implemented for objects of class '", class(x), "'")
}
add_subsampling_vars_to_pointwise <- function(pointwise, idxs, elpd_loo_approx) {
checkmate::assert_matrix(pointwise,
any.missing = FALSE,
min.cols = 5)
checkmate::assert_names(colnames(pointwise), identical.to = c("elpd_loo","mcse_elpd_loo","p_loo","looic", "influence_pareto_k"))
# assert_subsample_idxs(idxs)
checkmate::assert_numeric(elpd_loo_approx)
pw <- cbind(as.data.frame(pointwise), idxs)
pw$elpd_loo_approx <- elpd_loo_approx[idxs$idx]
pw <- as.matrix(pw)
rownames(pw) <- NULL
#assert_subsampling_pointwise(pw)
pw
}
loo_subsample_estimation_diff_srs <- function(x) {
checkmate::assert_class(x, "psis_loo_ss")
elpd_loo_est <- srs_diff_est(y_approx = x$loo_subsampling$elpd_loo_approx, y = x$pointwise[, "elpd_loo"], y_idx = x$pointwise[, "idx"])
x$estimates["elpd_loo", "Estimate"] <- elpd_loo_est$y_hat
x$estimates["elpd_loo", "SE"] <- sqrt(elpd_loo_est$hat_v_y)
x$estimates["elpd_loo", "subsampling SE"] <- sqrt(elpd_loo_est$v_y_hat)
p_loo_est <- srs_est(y = x$pointwise[, "p_loo"], y_approx = x$loo_subsampling$elpd_loo_approx)
x$estimates["p_loo", "Estimate"] <- p_loo_est$y_hat
x$estimates["p_loo", "SE"] <- sqrt(p_loo_est$hat_v_y)
x$estimates["p_loo", "subsampling SE"] <- sqrt(p_loo_est$v_y_hat)
update_psis_loo_ss_estimates(x)
}
srs_diff_est <- function(y_approx, y, y_idx) {
checkmate::assert_numeric(y_approx)
checkmate::assert_numeric(y, max.len = length(y_approx))
checkmate::assert_integerish(y_idx, len = length(y))
N <- length(y_approx)
m <- length(y)
y_approx_m <- y_approx[y_idx]
e_i <- y - y_approx_m
t_pi_tilde <- sum(y_approx)
t_pi2_tilde <- sum(y_approx^2)
t_e <- N * mean(e_i)
t_hat_epsilon <- N * mean(y^2 - y_approx_m^2)
est_list <- list(m = length(y), N = N)
est_list$y_hat <- t_pi_tilde + t_e
est_list$v_y_hat <- N^2 * (1 - m / N) * var(e_i) / m
est_list$hat_v_y <- (t_pi2_tilde + t_hat_epsilon) - # a (has been checked)
(1/N) * (t_e^2 - est_list$v_y_hat + 2 * t_pi_tilde * est_list$y_hat - t_pi_tilde^2) # b
est_list
}
srs_est <- function(y, y_approx) {
checkmate::assert_numeric(y)
checkmate::assert_numeric(y_approx, min.len = length(y))
N <- length(y_approx)
m <- length(y)
est_list <- list(m = m)
est_list$y_hat <- N * mean(y)
est_list$v_y_hat <- N^2 * (1-m/N) * var(y)/m
est_list$hat_v_y <- N * var(y)
est_list
}
update_psis_loo_ss_estimates <- function(x) {
checkmate::assert_class(x, "psis_loo_ss")
x$estimates["looic", "Estimate"] <- (-2) * x$estimates["elpd_loo", "Estimate"]
x$estimates["looic", "SE"] <- 2 * x$estimates["elpd_loo", "SE"]
x$estimates["looic", "subsampling SE"] <- 2 * x$estimates["elpd_loo", "subsampling SE"]
x$elpd_loo <- x$estimates["elpd_loo", "Estimate"]
x$p_loo <- x$estimates["p_loo", "Estimate"]
x$looic <- x$estimates["looic", "Estimate"]
x$se_elpd_loo <- x$estimates["elpd_loo", "SE"]
x$se_p_loo <- x$estimates["p_loo", "SE"]
x$se_looic <- x$estimates["looic", "SE"]
x
}
assert_psis_loo_ss <- function(x) {
checkmate::assert_class(x, "psis_loo_ss")
checkmate::assert_names(names(x), must.include = c("estimates", "pointwise", "diagnostics", "psis_object", "loo_subsampling"))
checkmate::assert_names(rownames(x$estimates), must.include = c("elpd_loo", "p_loo", "looic"))
checkmate::assert_names(colnames(x$estimates), must.include = c("Estimate", "SE", "subsampling SE"))
assert_subsampling_pointwise(x$pointwise)
checkmate::assert_names(names(x$loo_subsampling),
must.include = c("elpd_loo_approx",
"loo_approximation", "loo_approximation_draws",
"estimator",
"data_dim", "ndraws"))
checkmate::assert_numeric(x$loo_subsampling$elpd_loo_approx, any.missing = FALSE, len = x$loo_subsampling$data_dim[1])
checkmate::assert_choice(x$loo_subsampling$loo_approximation, choices = loo_approximation_choices(api = FALSE))
checkmate::assert_int(x$loo_subsampling$loo_approximation_draws, null.ok = TRUE)
checkmate::assert_choice(x$loo_subsampling$estimator, choices = estimator_choices())
checkmate::assert_integer(x$loo_subsampling$data_dim, any.missing = TRUE, len = 2)
checkmate::assert_int(x$loo_subsampling$data_dim[1], na.ok = FALSE)
checkmate::assert_integer(x$loo_subsampling$ndraws, len = 1, any.missing = TRUE)
x
}
assert_subsampling_pointwise <- function(x) {
checkmate::assert_matrix(x,
any.missing = FALSE,
ncols = 8)
checkmate::assert_names(colnames(x), identical.to = c("elpd_loo", "mcse_elpd_loo", "p_loo", "looic", "influence_pareto_k", "idx", "m_i", "elpd_loo_approx"))
x
}
loo_ss <- psis_loo_ss_object(x = loo_obj,
idxs = idxs,
elpd_loo_approx = elpd_loo_approx,
loo_approximation = 'plpd',
loo_approximation_draws = NULL,
estimator = "diff_srs",
.llfun = llfun_logistic,
.llgrad = NULL,
.llhess = NULL,
data_dim = dim(data),
ndraws = .ndraws(draws))
data_subsample <- data[idxs$idx,, drop = FALSE]
if (length(r_eff) > 1) {
r_eff <- r_eff[idxs$idx]
}
loo_obj <- loo.function(
x = llfun_logistic,
data = data_subsample,
draws = draws,
r_eff = r_eff,
#save_psis = save_psis,
#cores = cores
)
r_eff <- relative_eff(llfun_logistic,
log = FALSE, # relative_eff wants likelihood not log-likelihood values
chain_id = rep(1:4, each = 1000),
data = stan_df_1,
draws = parameter_draws_1,
cores = 4)
data_subsample <- data[idxs$idx,, drop = FALSE]
if (length(r_eff) > 1) {
r_eff <- r_eff[idxs$idx]
}
loo_obj <- loo.function(
x = llfun_logistic,
data = data_subsample,
draws = draws,
r_eff = r_eff,
#save_psis = save_psis,
#cores = cores
)
View(loo_obj)
View(loo_ss_1)
rm(list = ls())
library(tidyverse)
library(rstan)
library(loo)
# we'll add an argument log to toggle whether this is a log-likelihood or
# likelihood function. this will be useful later in the vignette.
llfun_logistic <- function(data_i, draws, log = TRUE) {
x_i <- as.matrix(data_i[, which(grepl(colnames(data_i), pattern = "X")), drop=FALSE])
logit_pred <- draws %*% t(x_i)
dbinom(x = data_i$y, size = 1, prob = 1/(1 + exp(-logit_pred)), log = log)
}
# Prepare data
# url <- "http://stat.columbia.edu/~gelman/arm/examples/arsenic/wells.dat"
# wells <- read.table(url)
# save(wells, file = "wells.Rdata")
# wells$dist100 <- with(wells, dist / 100)
load("wells.Rdata")
X <- model.matrix(~ dist100 + arsenic, wells)
standata <- list(y = wells$switch, X = X, N = nrow(X), P = ncol(X))
# Compile
stan_mod <- stan_model("logistic.stan")
# cmdsta_mod <- cmdstan_model("logistic.stan")
# Fit model
fit_1 <- sampling(stan_mod, data = standata, seed = 4711, cores = 4)
# fit_2 <- cmdsta_mod$sample(
#   data = standata,
#   seed = 4711,
#   chains = 4,
#   parallel_chains = 4,
#   refresh = 500 # print update every 500 iters
# )
print(fit_1, pars = "beta")
parameter_draws_1 <- extract(fit_1)$beta
# used for data argument to loo_i
stan_df_1 <- as.data.frame(standata)
r_eff <- relative_eff(llfun_logistic,
log = FALSE, # relative_eff wants likelihood not log-likelihood values
chain_id = rep(1:4, each = 1000),
data = stan_df_1,
draws = parameter_draws_1,
cores = 4)
loo_i(i = 1, llfun_logistic, r_eff = r_eff, data = stan_df_1, draws = parameter_draws_1)
# subsampling
set.seed(4711)
loo_ss_1 <-
loo_subsample(
llfun_logistic,
observations = 100, # take a subsample of size 100
cores = 2,
# these next objects were computed above
r_eff = r_eff,
draws = parameter_draws_1,
data = stan_df_1
)
print(loo_ss_1)
loo_ss_1
# used for draws argument to loo_i
parameter_draws_1 <- extract(fit_1)$beta
# used for data argument to loo_i
stan_df_1 <- as.data.frame(standata)
i <- 1
data_i <- stan_df_1[i, ]    # must be a dataframe
draws <- parameter_draws_1  # 4000 * 3
x_i <- as.matrix(data_i[, which(grepl(colnames(data_i), pattern = "X")), drop=FALSE])  # get the parameters 1*3
logit_pred <- draws %*% t(x_i) # matrix multiplication 4000 * 3 %*% 3 * 1
tmp <- dbinom(x = data_i$y, size = 1, prob = 1/(1 + exp(-logit_pred)), log = log)
draws <- parameter_draws_1  # 4000 * 3
data <- stan_df_1
llfun <- llfun_logistic
N <- dim(data)[1]
estimator <- "diff_srs"
loo_approximation = 'plpd'
observations <- 100
# here we replace the function .compute_point_estimate.matrix, which basically compute the means of parameters and transpose
tmp_compute_point_estimate <- function(draws) {
t(as.matrix(colMeans(draws)))
}
point_est <- tmp_compute_point_estimate(draws)
##  elpd_loo_approx <- elpd_loo_approximation ()...
# draws <- .thin_draws(draws, loo_approximation_draws)
# here we define compute_lpds and related function (lpd_i, logMeanExp) so that we can
# reproduce the elpd_loo_approximation part, which returns a vector of lpds
# https://github.com/stan-dev/loo/blob/e197aa7c5ac56881ad67dae3f90479af96d83c0a/R/helpers.R#L13
logMeanExp <- function(x) {
logS <- log(length(x))
matrixStats::logSumExp(x) - logS
}
lpd_i <- function(i, llfun, data, draws) {
ll_i <- llfun(data_i = data[i,, drop=FALSE], draws = draws)
ll_i <- as.vector(ll_i)
lpd_i <- logMeanExp(ll_i)
lpd_i
}
compute_lpds <- function(N, data, draws, llfun, cores) {
if (cores == 1) {
lpds <- lapply(X = seq_len(N), FUN = lpd_i, llfun, data, draws)
} else {
if (.Platform$OS.type != "windows") {
lpds <- parallel::mclapply(X = seq_len(N), mc.cores = cores, FUN = lpd_i, llfun, data, draws)
} else {
cl <- makePSOCKcluster(cores)
on.exit(stopCluster(cl))
lpds <- parLapply(cl, X = seq_len(N), fun = lpd_i, llfun, data, draws)
}
}
unlist(lpds)
}
elpd_loo_approx <- compute_lpds(N, data, point_est, llfun_logistic, cores=1)
elpd_loo_approximation <- elpd_loo_approx
# understand order()
set.seed(123)
tmp2 <- stats::runif(10)
order(tmp2)
tmp2[order(tmp2)]
#
subsample_idxs <- function(estimator, elpd_loo_approximation, observations) {
if (estimator == "hh_pps") {
pi_values <- pps_elpd_loo_approximation_to_pis(elpd_loo_approximation)
idxs_df <- pps_sample(observations, pis = pi_values)
}
if (estimator == "diff_srs" | estimator == "srs") {
if (observations > length(elpd_loo_approximation)) {
stop("'observations' is larger than the total sample size in 'data'.", call. = FALSE)
}
idx <- 1:length(elpd_loo_approximation)
# order function here is not the real ranking of data, but how to get those data so that the new a[order(a)] is ascending.
idx_m <- idx[order(stats::runif(length(elpd_loo_approximation)))][1:observations]
idx_m <- idx_m[order(idx_m)]
idxs_df <- data.frame(idx=as.integer(idx_m), m_i=1L)
}
# assert_subsample_idxs(x = idxs_df)
idxs_df
}
observations <- 100
idxs <- subsample_idxs(
estimator = "diff_srs", # here the default is simple random sampling (srs), i.e. randomly sub-sample
elpd_loo_approximation = elpd_loo_approx,
observations = observations)
data_subsample <- data[idxs$idx,, drop = FALSE]
if (length(r_eff) > 1) {
r_eff <- r_eff[idxs$idx]
}
loo_obj <- loo.function(
x = llfun_logistic,
data = data_subsample,
draws = draws,
r_eff = r_eff,
#save_psis = save_psis,
#cores = cores
)
View(loo_obj)
View(loo_obj)
loo_obj$pointwise
loo_obj$pointwise[,"idx"]
x_tmp <- loo_obj
x_tmp$pointwise <- add_subsampling_vars_to_pointwise(pointwise = x_tmp$pointwise, idxs=idxs, elpd_loo_approx= elpd_loo_approx)
# The third layer functions
add_subsampling_vars_to_pointwise <- function(pointwise, idxs, elpd_loo_approx) {
checkmate::assert_matrix(pointwise,
any.missing = FALSE,
min.cols = 5)
checkmate::assert_names(colnames(pointwise), identical.to = c("elpd_loo","mcse_elpd_loo","p_loo","looic", "influence_pareto_k"))
# assert_subsample_idxs(idxs)
checkmate::assert_numeric(elpd_loo_approx)
pw <- cbind(as.data.frame(pointwise), idxs)
pw$elpd_loo_approx <- elpd_loo_approx[idxs$idx]
pw <- as.matrix(pw)
rownames(pw) <- NULL
#assert_subsampling_pointwise(pw)
pw
}
x_tmp$pointwise <- add_subsampling_vars_to_pointwise(pointwise = x_tmp$pointwise, idxs=idxs, elpd_loo_approx= elpd_loo_approx)
View(x_tmp)
colnames(x_tmp$pointwise)
x_tmp$pointwise$idx
x_tmp$pointwise[,"idx"]
colnames(loo_obj$pointwise)
idxs
View(x_tmp)
head(x_tmp$pointwise)
loo_approximation
loo_approximation_draws
estimator
.llfun
data_dim
ndraws
dim(data)
.ndraws(draws)
x_tmp$loo_subsampling <- list()
x_tmp$loo_subsampling$elpd_loo_approx <- elpd_loo_approx
x_tmp$loo_subsampling$loo_approximation <- loo_approximation
x_tmp$loo_subsampling["loo_approximation_draws"] <- list(NULL)
x_tmp$loo_subsampling$estimator <- estimator
x_tmp$loo_subsampling$.llfun <- llfun
x_tmp$loo_subsampling[".llgrad"] <- list(NULL)
x_tmp$loo_subsampling[".llhess"] <- list(NULL)
x_tmp$loo_subsampling$data_dim <- dim(data)
x_tmp$loo_subsampling$ndraws <- .ndraws(draws)
View(x_tmp)
View(loo_ss_1)
## core fucntion of srs_diff_est
y_approx_tmp <- x_tmp$loo_subsampling$elpd_loo_approx
y_tmp <- x_tmp$pointwise[, 'elpd_loo']
y_idx_tmp <- x_tmp$pointwise[, "idx"]
N <- length(y_approx)
N <- length(y_approx_tmp)
m <- length(y_tmp)
y_approx_m <- y_approx_tmp[y_idx_tmp]
e_i <- y_tmp - y_approx_m
t_pi_tilde <- sum(y_approx_tmp)
t_pi2_tilde <- sum(y_approx_tmp^2)
t_e <- N * mean(e_i)
t_hat_epsilon <- N * mean(y_tmp^2 - y_approx_m^2)
est_list <- list(m = length(y_tmp), N = N)
est_list$y_hat <- t_pi_tilde + t_e
est_list$v_y_hat <- N^2 * (1 - m / N) * var(e_i) / m
est_list$hat_v_y <- (t_pi2_tilde + t_hat_epsilon) - # a (has been checked)
(1/N) * (t_e^2 - est_list$v_y_hat + 2 * t_pi_tilde * est_list$y_hat - t_pi_tilde^2) # b
est_list
elpd_loo_est <- est_list
x_tmp$estimates
