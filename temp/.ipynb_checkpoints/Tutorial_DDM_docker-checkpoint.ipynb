{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5205ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/IPython/parallel.py:12: ShimWarning: The `IPython.parallel` package has been deprecated since IPython 4.0. You should import from ipyparallel instead.\n",
      "  warn(\"The `IPython.parallel` package has been deprecated since IPython 4.0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current HDDM version is:  0.8.0\n",
      "The current PyMC version is:  2.3.8\n",
      "The current ArviZ version is:  0.11.4\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# General packages for system, time, etc\n",
    "import os, time, csv\n",
    "import datetime\n",
    "from datetime import date\n",
    "import glob\n",
    "import feather  # for compiling files\n",
    "\n",
    "# scitnific computing and plotting\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# HDDM related packages\n",
    "import pymc as pm\n",
    "import hddm\n",
    "import kabuki\n",
    "import arviz as az\n",
    "print(\"The current HDDM version is: \", hddm.__version__)\n",
    "print(\"The current PyMC version is: \", pm.__version__)\n",
    "print(\"The current ArviZ version is: \", az.__version__)\n",
    "\n",
    "# parallel processing related\n",
    "from p_tqdm import p_map\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfef831b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from HDDMarviz import HDDMarviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd1cac6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subj_idx</th>\n",
       "      <th>stim</th>\n",
       "      <th>rt</th>\n",
       "      <th>response</th>\n",
       "      <th>theta</th>\n",
       "      <th>dbs</th>\n",
       "      <th>conf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3983</th>\n",
       "      <td>13</td>\n",
       "      <td>LL</td>\n",
       "      <td>1.450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.237166</td>\n",
       "      <td>0</td>\n",
       "      <td>HC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3984</th>\n",
       "      <td>13</td>\n",
       "      <td>WL</td>\n",
       "      <td>0.711</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.377450</td>\n",
       "      <td>0</td>\n",
       "      <td>LC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3985</th>\n",
       "      <td>13</td>\n",
       "      <td>WL</td>\n",
       "      <td>0.784</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.694194</td>\n",
       "      <td>0</td>\n",
       "      <td>LC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3986</th>\n",
       "      <td>13</td>\n",
       "      <td>LL</td>\n",
       "      <td>2.350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.546536</td>\n",
       "      <td>0</td>\n",
       "      <td>HC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3987</th>\n",
       "      <td>13</td>\n",
       "      <td>WW</td>\n",
       "      <td>1.250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.752388</td>\n",
       "      <td>0</td>\n",
       "      <td>HC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      subj_idx stim     rt  response     theta  dbs conf\n",
       "3983        13   LL  1.450       0.0 -1.237166    0   HC\n",
       "3984        13   WL  0.711       1.0 -0.377450    0   LC\n",
       "3985        13   WL  0.784       1.0 -0.694194    0   LC\n",
       "3986        13   LL  2.350       0.0 -0.546536    0   HC\n",
       "3987        13   WW  1.250       1.0  0.752388    0   HC"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cavanagh = hddm.load_csv(os.path.join(os.path.dirname(hddm.__file__), \n",
    "                                           'examples', \n",
    "                                           'cavanagh_theta_nn.csv'))\n",
    "data_cavanagh.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6417222a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 3 µs, total: 5 µs\n",
      "Wall time: 8.34 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# define a function to run model in parallel\n",
    "\n",
    "# M0_0: base model: simplified\n",
    "def ms0(id, df=None, samples=None, burn=None, thin=1, save_name=\"ms0\"): \n",
    "    # for HDDM models, adding this print func can prevent warnings that would occur\n",
    "    #  when running parallel processing in jupyter\n",
    "    print('running chain {:d} for model {}'.format(id, save_name))\n",
    "    import hddm\n",
    "    \n",
    "    dbname = save_name + '_chain_%i.db'%id \n",
    "    mname  = save_name + '_chain_%i'%id    \n",
    "    m = hddm.HDDM(df)\n",
    "    m.find_starting_values()\n",
    "    m.sample(samples, burn=burn, thin=thin, dbname=dbname, db='pickle') # it's neccessary to save the model data\n",
    "    m.save(mname)\n",
    "    \n",
    "    return m\n",
    "\n",
    "# M1: base model: full model\n",
    "def ms1(id, df=None, samples=None, burn=None, thin = 1, save_name=\"ms1\"): \n",
    "    print('running chain {:d} for model {}'.format(id, save_name))\n",
    "    import hddm\n",
    "    \n",
    "    dbname = save_name + '_chain_%i.db'%id \n",
    "    mname  = save_name + '_chain_%i'%id    \n",
    "    m = hddm.HDDM(df, include=['z', 'sv', 'sz', 'st'])\n",
    "    m.find_starting_values()\n",
    "    m.sample(samples, burn=burn, thin=thin, dbname=dbname, db='pickle') # it's neccessary to save the model data\n",
    "    m.save(mname)\n",
    "    \n",
    "    return m\n",
    "\n",
    "\n",
    "# M2: treat within-subj as between-subj: full model\n",
    "def ms2(id, df=None, samples=None, burn=None, thin = 1, save_name=\"ms2\"): \n",
    "    print('running chain {:d} for model {}'.format(id, save_name))\n",
    "    import hddm\n",
    "    \n",
    "    dbname = save_name + '_chain_%i.db'%id \n",
    "    mname  = save_name + '_chain_%i'%id    \n",
    "    m = hddm.HDDM(df, include=['z', 'sv', 'st', 'sz'], \n",
    "                  depends_on={'v': 'conf'})\n",
    "    m.find_starting_values()\n",
    "    m.sample(samples, burn=burn, dbname=dbname, db='pickle') # it's neccessary to save the model data\n",
    "    m.save(mname)\n",
    "    \n",
    "    return m\n",
    "\n",
    "\n",
    "# M3: regression model (varying intercept)\n",
    "def ms3(id, df=None, samples=None, burn=None, thin = 1, save_name=\"ms3\"): \n",
    "    print('running chain {:d} for model {}'.format(id, save_name))\n",
    "    import hddm\n",
    "    \n",
    "    dbname = save_name + '_chain_%i.db'%id \n",
    "    mname  = save_name + '_chain_%i'%id   \n",
    "    m = hddm.HDDMRegressor(df,  \n",
    "                           \"v ~ C(conf, Treatment('LC'))\", \n",
    "                           group_only_regressors=True,\n",
    "                           keep_regressor_trace=True,\n",
    "                           include=['z', 'sv', 'st', 'sz'])\n",
    "    m.find_starting_values()\n",
    "    m.sample(samples, burn=burn, thin=thin, dbname=dbname, db='pickle') # it's neccessary to save the model data\n",
    "    m.save(mname)\n",
    "    \n",
    "    return m\n",
    "\n",
    "# M4: regression model (varying intercept and slope)\n",
    "def ms4(id, df=None, samples=None, burn=None, thin = 1, save_name=\"ms4\"): \n",
    "    print('running chain {:d} for model {}'.format(id, save_name))\n",
    "    import hddm\n",
    "    \n",
    "    dbname = save_name + '_chain_%i.db'%id \n",
    "    mname  = save_name + '_chain_%i'%id   \n",
    "    m = hddm.HDDMRegressor(df,\n",
    "                           \"v ~ C(conf, Treatment('LC'))\", \n",
    "                           group_only_regressors=False,\n",
    "                           keep_regressor_trace=True,\n",
    "                           include=['z', 'sv', 'st', 'sz'])\n",
    "    m.find_starting_values()\n",
    "    m.sample(samples, burn=burn, thin=thin, dbname=dbname, db='pickle') # it's neccessary to save the model data\n",
    "    m.save(mname)\n",
    "    \n",
    "    return m\n",
    "\n",
    "# M5: regression model + theta as an additional predictor of `a`\n",
    "def ms5(id, df=None, samples=None, burn=None, thin = 1, save_name=\"ms5\"): \n",
    "    print('running chain {:d} for model {}'.format(id, save_name))\n",
    "    import hddm\n",
    "    \n",
    "    dbname = save_name + '_chain_%i.db'%id \n",
    "    mname  = save_name + '_chain_%i'%id\n",
    "    m = hddm.HDDMRegressor(df,\n",
    "                           \"a ~ theta:C(conf, Treatment('LC'))\",\n",
    "                           depends_on={'v': 'conf'},\n",
    "                           group_only_regressors=False,\n",
    "                           keep_regressor_trace=True,\n",
    "                           include=['z', 'sv', 'st', 'sz'])\n",
    "    m.find_starting_values()\n",
    "    m.sample(samples, burn=burn, thin=thin, dbname=dbname, db='pickle') # it's neccessary to save the model data\n",
    "    m.save(mname)\n",
    "    \n",
    "    return m\n",
    "\n",
    "# M6: Regression for both parameters\n",
    "def ms6(id, df=None, samples=None, burn=None, thin = 1, save_name=\"ms6\"): \n",
    "    print('running chain {:d} for model {}'.format(id, save_name))\n",
    "    import hddm\n",
    "    \n",
    "    dbname = save_name + '_chain_%i.db'%id \n",
    "    mname  = save_name + '_chain_%i'%id\n",
    "    a_reg = {'model': \"a ~ theta:C(conf, Treatment('LC'))\", 'link_func': lambda x: x}\n",
    "    v_reg = {'model': \"v ~ C(conf, Treatment('LC'))\", 'link_func': lambda x: x}\n",
    "    reg_descr = [a_reg, v_reg]\n",
    "    \n",
    "    m = hddm.HDDMRegressor(df,\n",
    "                           reg_descr,\n",
    "                           group_only_regressors=False,\n",
    "                           keep_regressor_trace=True,\n",
    "                           include=['z', 'sv', 'st', 'sz'])\n",
    "    m.find_starting_values()\n",
    "    m.sample(samples, burn=burn, thin=thin, dbname=dbname, db='pickle') # it's neccessary to save the model data\n",
    "    m.save(mname)\n",
    "    \n",
    "    return m\n",
    "\n",
    "# M7: Regression for both parameters\n",
    "def ms7(id, df=None, samples=None, burn=None, thin = 1, save_name=\"ms7\"): \n",
    "    print('running chain {:d} for model {}'.format(id, save_name))\n",
    "    import hddm\n",
    "    \n",
    "    dbname = save_name + '_chain_%i.db'%id \n",
    "    mname  = save_name + '_chain_%i'%id\n",
    "    a_reg = {'model': \"a ~ theta:C(conf, Treatment('LC')):C(dbs, Treatment('0'))\", 'link_func': lambda x: x}\n",
    "    v_reg = {'model': \"v ~ C(conf, Treatment('LC'))\", 'link_func': lambda x: x}\n",
    "    reg_descr = [a_reg, v_reg]\n",
    "    \n",
    "    m = hddm.HDDMRegressor(df,\n",
    "                           reg_descr,\n",
    "                           group_only_regressors=False,\n",
    "                           keep_regressor_trace=True,\n",
    "                           include=['z', 'sv', 'st', 'sz'])\n",
    "    m.find_starting_values()\n",
    "    m.sample(samples, burn=burn, thin=thin, dbname=dbname, db='pickle') # it's neccessary to save the model data\n",
    "    m.save(mname)\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0262bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 300  # Cavanagh et al. 2011 used 30,000 and 10, 000 burn.\n",
    "burn = 100     \n",
    "nppc = 50     # 1000 samples for posterior predictive, super slow\n",
    "thin = 1\n",
    "chains = 4\n",
    "test_mode = False\n",
    "savefile=True\n",
    "savetag = \"tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2449c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 ns, sys: 2 µs, total: 3 µs\n",
      "Wall time: 6.91 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## total time: 5h 19s when test_mode is False\n",
    "\n",
    "## Step 1: run models in parallel\n",
    "file_path = \"/home/jovyan/hddm/temp/\"\n",
    "\n",
    "if test_mode:\n",
    "    model_func = ms0\n",
    "\n",
    "else: \n",
    "    model_func = [ms0,  \n",
    "                  ms4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db2911c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callable(model_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20690f2d",
   "metadata": {},
   "source": [
    "note: here we have problems when running parallel processing in jupyter, the issue here is similar to here: https://github.com/tqdm/tqdm/issues/485. I need to figure it out which function can be hacked with `print()`.\n",
    "\n",
    "Note: when model is ms0, there will be a warning about msg_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "471825b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model_func[0]\n",
    "# m_key = model.__name__  # get the model function's name\n",
    "# save_name_m = m_key + \"_\" + savetag\n",
    "# print(save_name_m)\n",
    "\n",
    "# ms_tmp = p_map(partial(model,\n",
    "#                        df=data_cavanagh, \n",
    "#                        samples=samples,\n",
    "#                        burn=burn,\n",
    "#                        thin=thin, \n",
    "#                        save_name=save_name_m),\n",
    "#                    range(chains))\n",
    "\n",
    "# xdata_post_pred = [] # define an empty dict    \n",
    "\n",
    "# xdata_post_pred = p_map(partial(post_pred_gen, samples = nppc), models['ms0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e8f669",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start model fitting for ms0\n",
      "running chain 0 for model ms0_tmp\n",
      "\n",
      "running chain 2 for model ms0_tmprunning chain 1 for model ms0_tmp"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b6cc377026d42c8b3e86910450f37c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "running chain 3 for model ms0_tmp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/scipy/optimize/optimize.py:2215: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  tmp2 = (x - v) * (fx - fw)\n",
      "/opt/conda/lib/python3.8/site-packages/scipy/optimize/optimize.py:2215: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  tmp2 = (x - v) * (fx - fw)\n",
      "/opt/conda/lib/python3.8/site-packages/scipy/optimize/optimize.py:2215: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  tmp2 = (x - v) * (fx - fw)\n",
      "/opt/conda/lib/python3.8/site-packages/scipy/optimize/optimize.py:2215: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  tmp2 = (x - v) * (fx - fw)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -                 4%                  ] 12 of 300 complete in 0.5 secc [-                 4%                  ] 13 of 300 complete in 0.5 sec[-                 4%                  ] 12 of 300 complete in 0.5 sec[--                7%                  ] 23 of 300 complete in 1.0 sec[---               8%                  ] 24 of 300 complete in 1.0 sec[--                7%                  ] 23 of 300 complete in 1.0 sec[---               8%                  ] 24 of 300 complete in 1.1 sec[----             11%                  ] 35 of 300 complete in 1.5 sec[----             11%                  ] 34 of 300 complete in 1.5 sec[----             12%                  ] 36 of 300 complete in 1.6 sec[----             11%                  ] 35 of 300 complete in 1.6 sec[-----            15%                  ] 45 of 300 complete in 2.0 sec[-----            15%                  ] 47 of 300 complete in 2.1 sec[-----            15%                  ] 47 of 300 complete in 2.1 sec[-----            15%                  ] 47 of 300 complete in 2.1 sec[-------          18%                  ] 56 of 300 complete in 2.5 sec[-------          19%                  ] 58 of 300 complete in 2.6 sec[-------          19%                  ] 59 of 300 complete in 2.6 sec[-------          19%                  ] 59 of 300 complete in 2.6 sec[--------         22%                  ] 67 of 300 complete in 3.1 sec[--------         23%                  ] 69 of 300 complete in 3.1 sec[--------         23%                  ] 70 of 300 complete in 3.2 sec[--------         23%                  ] 69 of 300 complete in 3.1 sec[---------        26%                  ] 78 of 300 complete in 3.6 sec[----------       27%                  ] 81 of 300 complete in 3.7 sec[----------       27%                  ] 82 of 300 complete in 3.7 sec[----------       27%                  ] 81 of 300 complete in 3.7 sec[-----------      29%                  ] 89 of 300 complete in 4.1 sec[-----------      30%                  ] 92 of 300 complete in 4.2 sec[-----------      31%                  ] 94 of 300 complete in 4.3 sec[-----------      30%                  ] 92 of 300 complete in 4.2 sec[------------     33%                  ] 100 of 300 complete in 4.6 sec[-------------    35%                  ] 105 of 300 complete in 4.8 sec[-------------    34%                  ] 103 of 300 complete in 4.8 sec[-------------    34%                  ] 103 of 300 complete in 4.7 sec[--------------   37%                  ] 111 of 300 complete in 5.2 sec[--------------   38%                  ] 114 of 300 complete in 5.3 sec[--------------   38%                  ] 116 of 300 complete in 5.3 sec[--------------   38%                  ] 114 of 300 complete in 5.3 sec[---------------  40%                  ] 122 of 300 complete in 5.7 sec[---------------- 42%                  ] 127 of 300 complete in 5.8 sec[---------------  42%                  ] 126 of 300 complete in 5.8 sec[---------------  41%                  ] 125 of 300 complete in 5.8 sec[---------------- 44%                  ] 132 of 300 complete in 6.2 sec[-----------------45%                  ] 137 of 300 complete in 6.3 sec[-----------------46%                  ] 138 of 300 complete in 6.4 sec[-----------------45%                  ] 136 of 300 complete in 6.4 sec[-----------------47%                  ] 142 of 300 complete in 6.7 sec[-----------------49%                  ] 148 of 300 complete in 6.8 sec[-----------------49%                  ] 149 of 300 complete in 6.9 sec[-----------------48%                  ] 146 of 300 complete in 6.9 sec[-----------------50%                  ] 152 of 300 complete in 7.2 sec[-----------------53%                  ] 160 of 300 complete in 7.4 sec[-----------------53%                  ] 160 of 300 complete in 7.4 sec[-----------------52%                  ] 157 of 300 complete in 7.4 sec[-----------------54%                  ] 163 of 300 complete in 7.8 sec[-----------------57%-                 ] 171 of 300 complete in 7.9 sec[-----------------57%-                 ] 171 of 300 complete in 8.0 sec[-----------------56%-                 ] 168 of 300 complete in 8.0 sec[-----------------57%-                 ] 173 of 300 complete in 8.3 sec[-----------------60%---               ] 182 of 300 complete in 8.4 sec[-----------------60%---               ] 182 of 300 complete in 8.5 sec[-----------------59%--                ] 178 of 300 complete in 8.5 sec[-----------------61%---               ] 184 of 300 complete in 8.8 sec[-----------------64%----              ] 193 of 300 complete in 9.0 sec[-----------------64%----              ] 193 of 300 complete in 9.0 sec[-----------------63%---               ] 189 of 300 complete in 9.0 sec[-----------------65%----              ] 195 of 300 complete in 9.4 sec[-----------------68%-----             ] 204 of 300 complete in 9.5 sec[-----------------68%-----             ] 204 of 300 complete in 9.5 sec[-----------------66%-----             ] 200 of 300 complete in 9.6 sec[-----------------68%------            ] 206 of 300 complete in 9.9 sec[-----------------71%-------           ] 215 of 300 complete in 10.0 sec[-----------------71%-------           ] 215 of 300 complete in 10.1 sec[-----------------70%------            ] 211 of 300 complete in 10.1 sec[-----------------72%-------           ] 216 of 300 complete in 10.4 sec[-----------------75%--------          ] 227 of 300 complete in 10.5 sec[-----------------75%--------          ] 226 of 300 complete in 10.6 sec[-----------------74%--------          ] 222 of 300 complete in 10.6 sec[-----------------75%--------          ] 226 of 300 complete in 10.9 sec[-----------------79%----------        ] 238 of 300 complete in 11.0 sec[-----------------79%----------        ] 237 of 300 complete in 11.1 sec[-----------------77%---------         ] 233 of 300 complete in 11.2 sec[-----------------78%---------         ] 236 of 300 complete in 11.4 sec[-----------------83%-----------       ] 249 of 300 complete in 11.5 sec[-----------------82%-----------       ] 248 of 300 complete in 11.6 sec[-----------------81%----------        ] 243 of 300 complete in 11.7 sec[-----------------82%-----------       ] 247 of 300 complete in 12.0 sec[-----------------87%-------------     ] 261 of 300 complete in 12.1 sec[-----------------86%------------      ] 259 of 300 complete in 12.1 sec"
     ]
    }
   ],
   "source": [
    "models, InfData = HDDMarviz(data=data_cavanagh, \n",
    "                            model_func=model_func,\n",
    "                            samples=samples, \n",
    "                            nppc=nppc, \n",
    "                            burn=burn, \n",
    "                            thin=thin, \n",
    "                            chains=chains, \n",
    "                            savefile=savefile,\n",
    "                            savetag=savetag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab55535",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99094fe",
   "metadata": {},
   "source": [
    "## Bayesian modelling with `ArviZ`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa94cd5",
   "metadata": {},
   "source": [
    "### Model diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54b0981",
   "metadata": {},
   "source": [
    "#### Visual inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308edf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "InfData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8139dc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from arviz.utils import Numba\n",
    "# Numba.disable_numba()\n",
    "# Numba.numba_flag\n",
    "az.plot_trace(InfData['ms0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a766da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     using regex to select var_names that start with \"a\" \n",
    "# and do not contain either \"subj\" or \"std\"\n",
    "\n",
    "az.plot_trace(InfData['ms4'], var_names=(\"^a(?!.*(subj|std))\"), filter_vars='regex')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19be206c",
   "metadata": {},
   "source": [
    "#### Using `az.summary()` to check $\\hat{R}$ and ESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb7992b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ms0_summary = az.summary(InfData['ms0'])\n",
    "ms0_summary.sort_values('r_hat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94955e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms4_summary = az.summary(InfData['ms4'])\n",
    "ms4_summary.sort_values('r_hat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858abc2e",
   "metadata": {},
   "source": [
    "### Model comparison and selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaed57a8",
   "metadata": {},
   "source": [
    "#### DIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba69965",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tmp_dic = []\n",
    "indx_name = []\n",
    "for m_key, model in models.items():\n",
    "#     print(len(models[key]))\n",
    "    m_tmp = kabuki.utils.concat_models(model)\n",
    "    tmp_dic.append(m_tmp.dic)\n",
    "    indx_name.append(m_key)\n",
    "#     print(m_key + \"'s DIC: \", m_tmp.dic) # model 4 has the lowest DIC\n",
    "    \n",
    "comp_dic = pd.DataFrame(tmp_dic, index=indx_name, columns=['dic'])\n",
    "comp_dic = comp_dic.sort_values(by=['dic'])\n",
    "comp_dic = comp_dic.reset_index()\n",
    "comp_dic.rename(columns={'index':'rank'}, inplace=True)\n",
    "comp_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b566f0e",
   "metadata": {},
   "source": [
    "#### PSIS-LOO-CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d2ac62",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "comp_loo = az.compare(InfData, ic='loo')\n",
    "comp_loo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfdd23e",
   "metadata": {},
   "source": [
    "####  WAIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f887581",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comp_waic = az.compare(InfData, ic='waic')\n",
    "comp_waic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656765cc",
   "metadata": {},
   "source": [
    "#### Posterior predictive check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674dcbdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "az.plot_ppc(InfData['ms0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6e5913",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_ppc(InfData['ms4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5569a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_ppc_by_cond import plot_ppc_by_cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673148df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_ppc_by_cond(data = InfData['ms4'],\n",
    "                 or_d = data_cavanagh,\n",
    "                 subjs = [3],\n",
    "#                  conds = ['conf'],\n",
    "                 conds = ['conf','dbs'],\n",
    "                 colors = ['r', 'k', 'b'],\n",
    "                 num_pp_samples=100,\n",
    "                 random_seed = 7,\n",
    "                 alpha = 0.2,\n",
    "                 grid = [2,2],\n",
    "                 var_names=['rt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7262f242",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_ppc_by_cond(data = InfData['ms0'],\n",
    "                 or_d = data_cavanagh,\n",
    "                 subjs = [3],\n",
    "#                  conds = ['conf'],\n",
    "                 conds = ['conf','dbs'],\n",
    "                 colors = ['r', 'k', 'b'],\n",
    "                 num_pp_samples=100,\n",
    "                 random_seed = 7,\n",
    "                 alpha = 0.2,\n",
    "                 grid = [2,2],\n",
    "                 var_names=['rt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa606c40",
   "metadata": {},
   "source": [
    "## Statistical Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bcde3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using regex to select var_names that start with \"a_theta\" and do not contain either \"subj\" or \"std\"\n",
    "az.plot_posterior(InfData['ms4'], \n",
    "                  var_names=(\"^v_(?!.*(subj|std))\"), \n",
    "                  filter_vars='regex',\n",
    "                  grid = [2, 2], \n",
    "                  kind = 'hist',\n",
    "                  hdi_prob = 0.95,\n",
    "                  rope = [0.45, 0.55], \n",
    "                  rope_color = 'r')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
