---
title: "Understand LOO-CV (subsampling)"
output: html_notebook
author: Hu Chuan-Peng
---
## Background
This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook for testing LOO-CV with subsampling. This script to understand the sub-sampling LOO and try to apply it for HDDM.

Example model is from [here](https://mc-stan.org/loo/articles/loo2-large-data.html).

Subsampling was largely derived from two papers:

* Magnusson, M., Riis Andersen, M., Jonasson, J. and Vehtari, A. (2020). Leave-One-Out Cross-Validation for Model Comparison in Large Data. Proceedings of the 23rd International Conference on Artificial Intelligence and Statistics (AISTATS), in PMLR 108. arXiv preprint arXiv:2001.00980.

* Magnusson, M., Andersen, M., Jonasson, J. & Vehtari, A. (2019). Bayesian leave-one-out cross-validation for large data. Proceedings of the 36th International Conference on Machine Learning, in PMLR 97:4244-4253 online, arXiv preprint arXiv:1904.10679.

The 2019 paper addressed the LOO in large dataset, using HH method, the 2020 further extended this method for model comparison, included the SRS method.

Six steps for subsampling in a single model:

* (1) Get the posterior, using any methods (In HDDM, we will not use approximation methods for now)
* (2) Compute $\hat{k}$ diagnostic for the posterior to assess the posterior approximation (not applicable here);
* (3) Compute $\tilde{\pi}$ for all $n$ observations.
* (4) Sample $m$ observations using PPS/SRS sampling and compute $log \hat{p}(y_i|y)$. Using $\hat{k}$ to diagnose the estimation of each $log \hat{p}(y_i|y)$.
* (5) Estimate $\widehat{elpd}_{loo}$, $v(\widehat{elpd}_{loo})$, and $\hat{\theta}_{loo}^2$.
* (6) repeat step 3 and 4 util sufficient precision is reached.

Five steps for model comparison:

* (1) Compute the posterior $p_A(\theta|y)$ and $p_B(\theta|y)$ for model A and B, respectively.
* (2) Compute $\tilde{\pi}$ for model A and B using an approximation that fulfill the properties in Sec. 2.2.
* (3) Compute the approximate difference as $\tilde{\pi}_{i, D} = \tilde{\pi}_{i, A} - \tilde{\pi}_{i, B}$ for all $n$.
* (4) Draw a subsample of size $m$ and compute $\tilde{\pi}_{j, D} = \tilde{\pi}_{j, A} - \tilde{\pi}_{j, B}$ for all $m$.
* (5) Estimate $elpd_D$ and $V(elpd_D)$ using Eq. (7) and (8)

## Preparation
```{r Loading libraries}
rm(list = ls())
library(tidyverse)
library(rstan)
library(loo)
```

## First, run the example
The example here is a model that predict the well-switching response given two predictors: the arsenic level of the water in the residentâ€™s home, and the distance of the house from the nearest safe well. 

Two-Step for subsampling. Step one is a normal MCMC, using stan, with three input:

* llfun: loglikelihood function;
* data: 
* Stan model:

Step two is the subsampleing, the input are:

* llfun:
* observation: size of subsample
* r_eff: relative effect sample size
* draws: posterior draw from MCMC
* data: the original data.

```{r subsampling example}
# we'll add an argument log to toggle whether this is a log-likelihood or 
# likelihood function. this will be useful later in the vignette.
llfun_logistic <- function(data_i, draws, log = TRUE) {
  x_i <- as.matrix(data_i[, which(grepl(colnames(data_i), pattern = "X")), drop=FALSE])
  logit_pred <- draws %*% t(x_i)
  dbinom(x = data_i$y, size = 1, prob = 1/(1 + exp(-logit_pred)), log = log)
}

# Prepare data
# url <- "http://stat.columbia.edu/~gelman/arm/examples/arsenic/wells.dat"
# wells <- read.table(url)
# save(wells, file = "wells.Rdata")
# wells$dist100 <- with(wells, dist / 100)
load("wells.Rdata")

X <- model.matrix(~ dist100 + arsenic, wells)
standata <- list(y = wells$switch, X = X, N = nrow(X), P = ncol(X))

# Compile
stan_mod <- stan_model("logistic.stan")

# Fit model
fit_1 <- sampling(stan_mod, data = standata, seed = 4711, cores = 4)

print(fit_1, pars = "beta")

parameter_draws_1 <- extract(fit_1)$beta

# used for data argument to loo_i
stan_df_1 <- as.data.frame(standata)

r_eff <- relative_eff(llfun_logistic, 
                      log = FALSE, # relative_eff wants likelihood not log-likelihood values
                      chain_id = rep(1:4, each = 1000), 
                      data = stan_df_1, 
                      draws = parameter_draws_1, 
                      cores = 4)

loo_i(i = 1, llfun_logistic, r_eff = r_eff, data = stan_df_1, draws = parameter_draws_1)
```

```{r}
start.time <- Sys.time()
# subsampling
set.seed(4711)
loo_ss_1 <-
  loo_subsample(
    llfun_logistic,
    observations = 100, # take a subsample of size 100
    cores = 2,
    # these next objects were computed above
    r_eff = r_eff, 
    draws = parameter_draws_1,
    data = stan_df_1
  )
time_loo_ss_1 <- Sys.time() - start.time
print(paste("Time taken: ", time_loo_ss_1, "secs"))
loo_ss_1
```

```{r}
start.time <- Sys.time()
# subsampling
set.seed(4711)
loo_ss_2 <-
  loo_subsample(
    llfun_logistic,
    observations = 100, # take a subsample of size 100
    cores = 2,
    # these next objects were computed above
    loo_approximation = 'tis',
    r_eff = r_eff, 
    draws = parameter_draws_1,
    data = stan_df_1
  )
time_loo_ss_2 <- Sys.time() - start.time
print(paste("Time taken: ", time_loo_ss_2, "secs"))
loo_ss_2
```

```{r}
start.time <- Sys.time()
set.seed(4711)
loo_1 <- loo(llfun_logistic,
    cores = 4,
    # these next objects were computed above
    r_eff = r_eff, 
    draws = parameter_draws_1,
    data = stan_df_1)
time_loo_1 <- Sys.time() - start.time
print(paste("Time taken: ", time_loo_1, "secs"))
loo_1
```
Comparing `loo_ss_1` and `loo_1`, we can see that the main different lies in the third column `subsampling_SE`, but the first two column is almost the same. However, the executing time is much faster for the subsampling with `plpd` method, the `pld` method will be even longer.

## Dissect the functions

### Log likelihood function
Understand the log likelihood function (`llfun`) in this example. It return point-wise log-likelihood for each data point, based on the input `data_i`.  Note that log likelihood function is different from the model, though the likelihood function is essential for MCMC in most models.

``` {r}
# used for draws argument to loo_i
parameter_draws_1 <- extract(fit_1)$beta

# used for data argument to loo_i
stan_df_1 <- as.data.frame(standata)

i <- 1
data_i <- stan_df_1[i, ]    # must be a dataframe
draws <- parameter_draws_1  # 4000 * 3
x_i <- as.matrix(data_i[, which(grepl(colnames(data_i), pattern = "X")), drop=FALSE])  # get the parameters 1*3
logit_pred <- draws %*% t(x_i) # matrix multiplication 4000 * 3 %*% 3 * 1
tmp <- dbinom(x = data_i$y, size = 1, prob = 1/(1 + exp(-logit_pred)), log = log)
```

### Subsampling step-by-step

#### Step 1: Preparing the inputs

```{r prepare inputs}
draws <- parameter_draws_1  # 4000 * 3
data <- stan_df_1
llfun <- llfun_logistic
N <- dim(data)[1]

estimator <- "diff_srs"
loo_approximation <- 'plpd'

observations <- 100
```

#### Step 2: get the point estimate

This is part of the `loo_approximation` in the `loo_subsample.R`. There are multiple ways to estimate these values, and the default is `plpd`.

* `tis` or `sis`: returns the `loo_epld` using `loo.function()` (i.e., no approximation at all)
* `lpd`: returns results of `compute_lpds`;
* `plpd`: returns results of `compute_lpds`, with an addition input of `point_est`;
* others: approximation methods.

Here we first check how the `point_est` is computed: first calculate the mean of each columns (i.e., the mean of posterior of each parameter), then convert it to a matrix (dim: 3x1 ), and then transpose it to a 1X3 matrix. Thus point estimate basically using the mean of posterior. 

This step is computing the $\hat{\theta}$ in the approximating the $\tilde{\pi} \propto -\text{log} p(y_i | \hat{\theta})$ (see section 2.5 in Magnusson et al. 2019).

Thus the `point_est` mean point estimation, i.e., means value, not point-wise estimation.

```{r pointwise estimate}
# here we replace the function .compute_point_estimate.matrix, which basically compute the means of parameters and transpose
tmp_compute_point_estimate <- function(draws) {
  t(as.matrix(colMeans(draws))) 
}

point_est <- tmp_compute_point_estimate(draws)
```

#### Step 3: Get the `elpd_loo_approx`

Here we start to use the `point_est` to estimate the `epld_loo_approx`. Basically, we replace the `draws` argument with `point_est` so that we only need three thetas for all data.

Essentially, it is a for loop, loop through the N data `llfun(data_i = data[i, , drop=FALSE], draws = draws)`, here only the mean of thetas are used to calculate the log-likelihood for each data point. After that, binding all the log-likelihood as a vector and calculate their `logMeanExp`. The question is: if we use the mean of thetas there, what's the difference between this verion of loo_cv and DIC?

`elpd_loo_approx` is a vector of the same length as the data (here: 3020)

```{r elpd_loo_approx}
##  elpd_loo_approx <- elpd_loo_approximation ()...
# draws <- .thin_draws(draws, loo_approximation_draws)

# here we define compute_lpds and related function (lpd_i, logMeanExp) so that we can 
# reproduce the elpd_loo_approximation part, which returns a vector of lpds

# https://github.com/stan-dev/loo/blob/e197aa7c5ac56881ad67dae3f90479af96d83c0a/R/helpers.R#L13
logMeanExp <- function(x) {
  logS <- log(length(x))
  matrixStats::logSumExp(x) - logS
}

lpd_i <- function(i, llfun, data, draws) {
  ll_i <- llfun(data_i = data[i,, drop=FALSE], draws = draws)
  ll_i <- as.vector(ll_i)
  lpd_i <- logMeanExp(ll_i)
  lpd_i
}

compute_lpds <- function(N, data, draws, llfun, cores) {
  if (cores == 1) {
    lpds <- lapply(X = seq_len(N), FUN = lpd_i, llfun, data, draws)
  } else {
    if (.Platform$OS.type != "windows") {
      lpds <- parallel::mclapply(X = seq_len(N), mc.cores = cores, FUN = lpd_i, llfun, data, draws)
    } else {
      cl <- makePSOCKcluster(cores)
      on.exit(stopCluster(cl))
      lpds <- parLapply(cl, X = seq_len(N), fun = lpd_i, llfun, data, draws)
    }
  }
  
  unlist(lpds)
}

elpd_loo_approx <- compute_lpds(N, data, point_est, llfun_logistic, cores=1)

elpd_loo_approximation <- elpd_loo_approx
```

#### Step 4: get subsample_idxs

Here we only use the default approach `diff_srs`.

`diff_srs` use the simple random sampling without replacement (SRS), which basically randomly choose a subset of data. In this approach, the subset index was generated from ordering a uniform distribution with the same length of the `epld_loo_approx`, and then select the first subset with length of subsample size (which is defined by observation).

It's different from the `hh_pps` approach, with use the proportion to sample the subset. However, the advantage of `srs` is that it can be used for model comparison

```{r subsample_idxs}
# understand order()
set.seed(123)
tmp2 <- stats::runif(10)
order(tmp2)
tmp2[order(tmp2)]
#

subsample_idxs <- function(estimator, elpd_loo_approximation, observations) {
  if (estimator == "hh_pps") {
    pi_values <- pps_elpd_loo_approximation_to_pis(elpd_loo_approximation)
    idxs_df <- pps_sample(observations, pis = pi_values)
  }

  if (estimator == "diff_srs" | estimator == "srs") {
    if (observations > length(elpd_loo_approximation)) {
      stop("'observations' is larger than the total sample size in 'data'.", call. = FALSE)
    }
    idx <- 1:length(elpd_loo_approximation)
    # order function here is not the real ranking of data, but how to get those data so that the new a[order(a)] is ascending.
    idx_m <- idx[order(stats::runif(length(elpd_loo_approximation)))][1:observations]
    idx_m <- idx_m[order(idx_m)]
    idxs_df <- data.frame(idx=as.integer(idx_m), m_i=1L)
  }
  # assert_subsample_idxs(x = idxs_df)
  idxs_df
}

observations <- 100
idxs <- subsample_idxs(
        estimator = "diff_srs", # here the default is simple random sampling (srs), i.e. randomly sub-sample
        elpd_loo_approximation = elpd_loo_approx,
        observations = observations)
```

#### Step 5: Get the `loo_obj`
Here we will use sub set of data, subset of r_eff and all posterior (draws) for the `loo_obj`. Note that the result already include output of `loo`.

```{r get loo_obj}
data_subsample <- data[idxs$idx,, drop = FALSE]

if (length(r_eff) > 1) {
        r_eff <- r_eff[idxs$idx]
}

loo_obj <- loo.function(
        x = llfun_logistic,
        data = data_subsample,
        draws = draws,
        r_eff = r_eff,
        #save_psis = save_psis,
        #cores = cores
      )
```

#### Step 6: get the `loo_obj_ss`

This part is the most crucial one, in which the core function is `psis_loo_ss_object`.

The `psis_loo_ss_object` in turn include two most important functions: `add_subsampling_vars_to_pointwise`, `loo_subsample_estimation_diff_srs`. The later is important because we use the `diff_srs` method.

If we skip all the code that are used for checking or asserting, then, after `loo`, the default subsampling method boil downs to two import functions: `srs_diff_est()` and `srs_est()`.

`srs_diff_est()` takes three input: y_approx, which is the elpd_loo_approx, y, which is the `elpd_loo` from `loo()` function, and `y_idx`, which is the subsample index. `srs_est()` has two inputs: y, which is the `p_loo` from `loo()` function, and `y_approx`, which is also the elpd_loo_approx.

For `srs_diff_est()`, it will first get the length of all elpd_loo_approx (N), subsample length (m), and used the index to extract epld_loo_approx that corresponding the subsample. The formula is from Magnusson et al. (2020). More specifically, formula (7), (8), (9).

$$e_i = elpd_{loo-m} - elpd_{loo-approx-m} $$
$$\tilde{t_{\pi}} = \sum(elpd_{loo-approx})$$
$$\tilde{t_{\pi^2}} = \sum((elpd_{loo-approx})^2) $$
$$t_e = N * mean (e_i)$$
$$\hat{t_{\epsilon}} = N * mean(elpd_{loo-m} - elpd_{loo-approx-m}^2)$$

This is the final $elpd_{loo}$:
$$ \hat{y} = \tilde {t_{\pi}} + t_e = \sum (elpd_{loo-approx}) + N*mean(e_i)$$
This the final SE of $elpd_{loo}$:
$$Var{\hat{y} = N^2 * (1 - m / N) * var(e_i) / m }$$
This the final subsample SE of $elpd_{loo}$:
$$\hat{v_{y}} = (\tilde {t_{\pi^2}} + \hat{t_{\epsilon}}) - (1/N) * (t_e^2 - \hat{v_y} + 2 * \tilde {t_{\pi}}  * \hat {y} - \tilde {t_{\pi}}^2)$$

```{r get loo_obj_ss}
x_tmp <- loo_obj
## psis_loo_ss_object's core fucntion:
x_tmp$pointwise <- add_subsampling_vars_to_pointwise(pointwise = x_tmp$pointwise, idxs=idxs, elpd_loo_approx= elpd_loo_approx)

x_tmp$loo_subsampling <- list()
x_tmp$loo_subsampling$elpd_loo_approx <- elpd_loo_approx
x_tmp$loo_subsampling$loo_approximation <- loo_approximation
x_tmp$loo_subsampling["loo_approximation_draws"] <- list(NULL)
x_tmp$loo_subsampling$estimator <- estimator
x_tmp$loo_subsampling$.llfun <- llfun
x_tmp$loo_subsampling[".llgrad"] <- list(NULL)
x_tmp$loo_subsampling[".llhess"] <- list(NULL)
x_tmp$loo_subsampling$data_dim <- dim(data)
x_tmp$loo_subsampling$ndraws <- .ndraws(draws)

## core fucntion of srs_diff_est
y_approx_tmp <- x_tmp$loo_subsampling$elpd_loo_approx
y_tmp <- x_tmp$pointwise[, 'elpd_loo']
y_idx_tmp <- x_tmp$pointwise[, "idx"]

N <- length(y_approx_tmp)
m <- length(y_tmp)
y_approx_m <- y_approx_tmp[y_idx_tmp]

e_i <- y_tmp - y_approx_m
t_pi_tilde <- sum(y_approx_tmp)
t_pi2_tilde <- sum(y_approx_tmp^2)
t_e <- N * mean(e_i)
t_hat_epsilon <- N * mean(y_tmp^2 - y_approx_m^2)

est_list <- list(m = length(y_tmp), N = N)
est_list$y_hat <- t_pi_tilde + t_e
est_list$v_y_hat <- N^2 * (1 - m / N) * var(e_i) / m
est_list$hat_v_y <- (t_pi2_tilde + t_hat_epsilon) - # a (has been checked)
(1/N) * (t_e^2 - est_list$v_y_hat + 2 * t_pi_tilde * est_list$y_hat - t_pi_tilde^2) # b
elpd_loo_est <- est_list

# the most out layer
loo_ss <- psis_loo_ss_object(x = loo_obj,
                         idxs = idxs,
                         elpd_loo_approx = elpd_loo_approx,
                         loo_approximation = 'plpd',
                         loo_approximation_draws = NULL,
                         estimator = "diff_srs",
                         .llfun = llfun_logistic,
                         .llgrad = NULL,
                         .llhess = NULL,
                         data_dim = dim(data),
                         ndraws = .ndraws(draws))

# The second layer function
psis_loo_ss_object <- function(x,
                               idxs,
                               elpd_loo_approx,
                               loo_approximation, 
                               loo_approximation_draws,
                               estimator,
                               .llfun, .llgrad, .llhess,
                               data_dim, ndraws) {
  # Assertions
  checkmate::assert_class(x, "psis_loo")
  # assert_subsample_idxs(idxs)
  checkmate::assert_numeric(elpd_loo_approx, any.missing = FALSE)
  checkmate::assert_choice(loo_approximation, loo_approximation_choices())
  checkmate::assert_int(loo_approximation_draws, null.ok = TRUE)
  checkmate::assert_choice(estimator, estimator_choices())
  checkmate::assert_function(.llfun, args = c("data_i", "draws"), ordered = TRUE)
  checkmate::assert_function(.llgrad, args = c("data_i", "draws"), ordered = TRUE, null.ok = TRUE)
  checkmate::assert_function(.llhess, args = c("data_i", "draws"), ordered = TRUE, null.ok = TRUE)
  checkmate::assert_integer(data_dim, len = 2, lower = 1, any.missing = FALSE)
  checkmate::assert_int(ndraws, lower = 1)

  # Construct object
  class(x) <- c("psis_loo_ss", class(x))
  x$pointwise <- add_subsampling_vars_to_pointwise(pointwise = x$pointwise, idxs, elpd_loo_approx)
  x$estimates <- cbind(x$estimates, matrix(0, nrow = nrow(x$estimates)))
  colnames(x$estimates)[ncol(x$estimates)] <- "subsampling SE"

  x$loo_subsampling <- list()
  x$loo_subsampling$elpd_loo_approx <- elpd_loo_approx
  x$loo_subsampling$loo_approximation <- loo_approximation
  x$loo_subsampling["loo_approximation_draws"] <- list(loo_approximation_draws)
  x$loo_subsampling$estimator <- estimator
  x$loo_subsampling$.llfun <- .llfun
  x$loo_subsampling[".llgrad"] <- list(.llgrad)
  x$loo_subsampling[".llhess"] <- list(.llhess)
  x$loo_subsampling$data_dim <- data_dim
  x$loo_subsampling$ndraws <- ndraws

  # Compute estimates
  if (estimator == "hh_pps") {
    x <- loo_subsample_estimation_hh(x)
  } else if (estimator == "diff_srs") {
    x <- loo_subsample_estimation_diff_srs(x)
  } else if (estimator == "srs") {
    x <- loo_subsample_estimation_srs(x)
  } else {
    stop("No correct estimator used.")
  }
  assert_psis_loo_ss(x)
  x
}

# The third layer functions
add_subsampling_vars_to_pointwise <- function(pointwise, idxs, elpd_loo_approx) {
  ## This function added three columns: idx, m_i, elpd_loo_approx
  checkmate::assert_matrix(pointwise,
                           any.missing = FALSE,
                           min.cols = 5)
  checkmate::assert_names(colnames(pointwise), identical.to = c("elpd_loo","mcse_elpd_loo","p_loo","looic", "influence_pareto_k"))
  # assert_subsample_idxs(idxs)
  checkmate::assert_numeric(elpd_loo_approx)

  pw <- cbind(as.data.frame(pointwise), idxs) # idxs have two columns: idx and m_i
  pw$elpd_loo_approx <- elpd_loo_approx[idxs$idx]
  pw <- as.matrix(pw)
  rownames(pw) <- NULL
  #assert_subsampling_pointwise(pw)
  pw
}

assert_psis_loo_ss <- function(x) {
  checkmate::assert_class(x, "psis_loo_ss")
  checkmate::assert_names(names(x), must.include = c("estimates", "pointwise", "diagnostics", "psis_object", "loo_subsampling"))
  checkmate::assert_names(rownames(x$estimates), must.include = c("elpd_loo", "p_loo", "looic"))
  checkmate::assert_names(colnames(x$estimates), must.include = c("Estimate", "SE", "subsampling SE"))
  assert_subsampling_pointwise(x$pointwise)
  checkmate::assert_names(names(x$loo_subsampling),
                          must.include = c("elpd_loo_approx",
                                           "loo_approximation", "loo_approximation_draws",
                                           "estimator",
                                           "data_dim", "ndraws"))
  checkmate::assert_numeric(x$loo_subsampling$elpd_loo_approx, any.missing = FALSE, len = x$loo_subsampling$data_dim[1])
  checkmate::assert_choice(x$loo_subsampling$loo_approximation, choices = loo_approximation_choices(api = FALSE))
  checkmate::assert_int(x$loo_subsampling$loo_approximation_draws, null.ok = TRUE)
  checkmate::assert_choice(x$loo_subsampling$estimator, choices = estimator_choices())
  checkmate::assert_integer(x$loo_subsampling$data_dim, any.missing = TRUE, len = 2)
  checkmate::assert_int(x$loo_subsampling$data_dim[1], na.ok = FALSE)
  checkmate::assert_integer(x$loo_subsampling$ndraws, len = 1, any.missing = TRUE)
  x
}

loo_subsample_estimation_diff_srs <- function(x) {
  checkmate::assert_class(x, "psis_loo_ss")

  elpd_loo_est <- srs_diff_est(y_approx = x$loo_subsampling$elpd_loo_approx, y = x$pointwise[, "elpd_loo"], y_idx = x$pointwise[, "idx"])
  x$estimates["elpd_loo", "Estimate"] <- elpd_loo_est$y_hat
  x$estimates["elpd_loo", "SE"] <- sqrt(elpd_loo_est$hat_v_y)
  x$estimates["elpd_loo", "subsampling SE"] <- sqrt(elpd_loo_est$v_y_hat)

  p_loo_est <- srs_est(y = x$pointwise[, "p_loo"], y_approx = x$loo_subsampling$elpd_loo_approx)
  x$estimates["p_loo", "Estimate"] <- p_loo_est$y_hat
  x$estimates["p_loo", "SE"] <- sqrt(p_loo_est$hat_v_y)
  x$estimates["p_loo", "subsampling SE"] <- sqrt(p_loo_est$v_y_hat)

  update_psis_loo_ss_estimates(x)
}

# The forth layer for esetimation: srs_diff_est and srs_est
y_approx <- x_tmp$
srs_diff_est <- function(y_approx, y, y_idx) {
  checkmate::assert_numeric(y_approx)
  checkmate::assert_numeric(y, max.len = length(y_approx))
  checkmate::assert_integerish(y_idx, len = length(y))

  N <- length(y_approx)
  m <- length(y)
  y_approx_m <- y_approx[y_idx]

  e_i <- y - y_approx_m
  t_pi_tilde <- sum(y_approx)
  t_pi2_tilde <- sum(y_approx^2)
  t_e <- N * mean(e_i)
  t_hat_epsilon <- N * mean(y^2 - y_approx_m^2)

  est_list <- list(m = length(y), N = N)
  est_list$y_hat <- t_pi_tilde + t_e
  est_list$v_y_hat <- N^2 * (1 - m / N) * var(e_i) / m
  est_list$hat_v_y <- (t_pi2_tilde + t_hat_epsilon) - # a (has been checked)
    (1/N) * (t_e^2 - est_list$v_y_hat + 2 * t_pi_tilde * est_list$y_hat - t_pi_tilde^2) # b
  est_list
}

srs_est <- function(y, y_approx) {
  checkmate::assert_numeric(y)
  checkmate::assert_numeric(y_approx, min.len = length(y))
  N <- length(y_approx)
  m <- length(y)
  est_list <- list(m = m)
  est_list$y_hat <- N * mean(y)
  est_list$v_y_hat <- N^2 * (1-m/N) * var(y)/m
  est_list$hat_v_y <- N * var(y)

  est_list
}

# the forth layer function: update
update_psis_loo_ss_estimates <- function(x) {
  checkmate::assert_class(x, "psis_loo_ss")

  x$estimates["looic", "Estimate"] <- (-2) * x$estimates["elpd_loo", "Estimate"]
  x$estimates["looic", "SE"] <- 2 * x$estimates["elpd_loo", "SE"]
  x$estimates["looic", "subsampling SE"] <- 2 * x$estimates["elpd_loo", "subsampling SE"]

  x$elpd_loo <- x$estimates["elpd_loo", "Estimate"]
  x$p_loo <- x$estimates["p_loo", "Estimate"]
  x$looic <- x$estimates["looic", "Estimate"]
  x$se_elpd_loo <- x$estimates["elpd_loo", "SE"]
  x$se_p_loo <- x$estimates["p_loo", "SE"]
  x$se_looic <- x$estimates["looic", "SE"]

  x
}

assert_subsampling_pointwise <- function(x) {
  checkmate::assert_matrix(x,
                           any.missing = FALSE,
                           ncols = 8)
  checkmate::assert_names(colnames(x), identical.to = c("elpd_loo", "mcse_elpd_loo", "p_loo", "looic", "influence_pareto_k", "idx", "m_i", "elpd_loo_approx"))
  x
}

# other utilities:
loo_approximation_choices <- function(api = TRUE) {
  lac <- c("plpd", "lpd", "waic", "waic_grad_marginal", "waic_grad", "waic_hess", "tis", "sis", "none")
  if (!api) lac <- c(lac, "psis")
  lac
}

estimator_choices <- function() {
  c("hh_pps", "diff_srs", "srs")
}


.ndraws <- function(x) {
  UseMethod(".ndraws")
}

.ndraws.matrix <- function(x) {
  nrow(x)
}

.ndraws.default <- function(x) {
  stop(".ndraws() has not been implemented for objects of class '", class(x), "'")
}

```


```{r additional subsampling}
set.seed(4711)
loo_ss_1b <-
  update(
    loo_ss_1,
    observations = 200, # subsample 200 instead of 100
    r_eff = r_eff,
    draws = parameter_draws_1,
    data = stan_df_1
  ) 
print(loo_ss_1b)
```
```{r specify subsampling method}
set.seed(4711)
loo_ss_1c <-
  loo_subsample(
    x = llfun_logistic,
    r_eff = r_eff,
    draws = parameter_draws_1,
    data = stan_df_1,
    observations = 100,
    estimator = "hh_pps", # use Hansen-Hurwitz
    loo_approximation = "lpd", # use lpd instead of plpd
    loo_approximation_draws = 100,
    cores = 2
  )
print(loo_ss_1c)
```
