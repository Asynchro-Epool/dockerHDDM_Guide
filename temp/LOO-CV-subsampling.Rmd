---
title: "Understand LOO-CV (subsampling)"
output: html_notebook
author: Hu Chuan-Peng
---
## Background
This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook for testing LOO-CV with subsampling. This script to understand the sub-sampling LOO and try to apply it for HDDM.

Example model is from [here](https://mc-stan.org/loo/articles/loo2-large-data.html).

Subsampling was largely derived from two papers:

* Magnusson, M., Riis Andersen, M., Jonasson, J. and Vehtari, A. (2020). Leave-One-Out Cross-Validation for Model Comparison in Large Data. Proceedings of the 23rd International Conference on Artificial Intelligence and Statistics (AISTATS), in PMLR 108. arXiv preprint arXiv:2001.00980.

* Magnusson, M., Andersen, M., Jonasson, J. & Vehtari, A. (2019). Bayesian leave-one-out cross-validation for large data. Proceedings of the 36th International Conference on Machine Learning, in PMLR 97:4244-4253 online, arXiv preprint arXiv:1904.10679.

The 2019 paper addressed the LOO in large dataset, using HH method, the 2020 further extended this method for model comparison, included the SRS method.

Six steps for subsampling in a single model:

* (1) Get the posterior, using any methods (In HDDM, we will not use approximation methods for now)
* (2) Compute $\hat{k}$ diagnostic for the posterior to assess the posterior approximation (not applicable here);
* (3) Compute $\tilde{\pi}$ for all $n$ observations.
* (4) Sample $m$ observations using PPS/SRS sampling and compute $log \hat{p}(y_i|y)$. Using $\hat{k}$ to diagnose the estimation of each $log \hat{p}(y_i|y)$.
* (5) Estimate $\widehat{elpd}_{loo}$, $v(\widehat{elpd}_{loo})$, and $\hat{\theta}_{loo}^2$.
* (6) repeat step 3 and 4 util sufficient precision is reached.

Five steps for model comparison:

* (1) Compute the posterior $p_A(\theta|y)$ and $p_B(\theta|y)$ for model A and B, respectively.
* (2) Compute $\tilde{\pi}$ for model A and B using an approximation that fulfill the properties in Sec. 2.2.
* (3) Compute the approximate difference as $\tilde{\pi}_{i, D} = \tilde{\pi}_{i, A} - \tilde{\pi}_{i, B}$ for all $n$.
* (4) Draw a subsample of size $m$ and compute $\tilde{\pi}_{j, D} = \tilde{\pi}_{j, A} - \tilde{\pi}_{j, B}$ for all $m$.
* (5) Estimate $elpd_D$ and $V(elpd_D)$ using Eq. (7) and (8)

## Preparation
```{r Loading libraries}
rm(list = ls())
library(tidyverse)
library(rstan)
library(loo)
```

## First, run the example
The example here is a model that predict the well-switching response given two predictors: the arsenic level of the water in the residentâ€™s home, and the distance of the house from the nearest safe well. 

Two-Step for subsampling. Step one is a normal MCMC, using stan, with three input:

* llfun: loglikelihood function;
* data: data
* Stan model: stan file for a model.

Step two is the subsampling, the input are:

* llfun:
* observation: size of subsample
* r_eff: relative effect sample size
* draws: posterior draw from MCMC
* data: the original data.

```{r subsampling example}
# we'll add an argument log to toggle whether this is a log-likelihood or 
# likelihood function. this will be useful later in the vignette.
llfun_logistic <- function(data_i, draws, log = TRUE) {
  x_i <- as.matrix(data_i[, which(grepl(colnames(data_i), pattern = "X")), drop=FALSE])
  logit_pred <- draws %*% t(x_i)
  dbinom(x = data_i$y, size = 1, prob = 1/(1 + exp(-logit_pred)), log = log)
}

# Prepare data
# url <- "http://stat.columbia.edu/~gelman/arm/examples/arsenic/wells.dat"
# wells <- read.table(url)
# save(wells, file = "wells.Rdata")
# wells$dist100 <- with(wells, dist / 100)
load("wells.Rdata")

# write.csv(wells, file = "wells.csv", row.names = F)
X <- model.matrix(~ dist100 + arsenic, wells)
standata <- list(y = wells$switch, X = X, N = nrow(X), P = ncol(X))

# Compile
stan_mod <- stan_model("logistic.stan")

# Fit model
fit_1 <- sampling(stan_mod, data = standata, seed = 4711, cores = 4)

print(fit_1, pars = "beta")

parameter_draws_1 <- extract(fit_1)$beta

# used for data argument to loo_i
stan_df_1 <- as.data.frame(standata)

r_eff <- relative_eff(llfun_logistic, 
                      log = FALSE, # relative_eff wants likelihood not log-likelihood values
                      chain_id = rep(1:4, each = 1000), 
                      data = stan_df_1, 
                      draws = parameter_draws_1, 
                      cores = 4)

loo_i(i = 1, llfun_logistic, r_eff = r_eff, data = stan_df_1, draws = parameter_draws_1)
```

```{r understand r_eff}
chain_id <- rep(1:4, each=1000)
data <- stan_df_1
draws <- parameter_draws_1
x <- llfun_logistic
N <- dim(data)[1]

n_eff_list <-
        lapply(
          X = seq_len(N),
          FUN = function(i) {
            val_i <- llfun_logistic(data_i = data[i, , drop = FALSE], draws = draws)
            #relative_eff.default(as.vector(val_i), chain_id = chain_id, cores = 1)
          }
        )

data_i <- data[1, , drop = FALSE]
tmp <- llfun_logistic(data_i = data_i, draws = draws)
mean(tmp)

data_2 <- data[2, , drop = FALSE]
tmp2 <- llfun_logistic(data_i = data_2, draws = draws)
mean(tmp2)

tmp_ <- as.vector(tmp2)

dim(tmp_) <- c(length(tmp_), 1)
class(tmp_) <- "matrix"

tmp_0 <- llmatrix_to_array(tmp_, chain_id) # from matrix to 1000 * 4 * 3020 array

length(dim(tmp_0)) == 3

S <- prod(dim(tmp_0)[1:2]) 
 
n_eff_vec <- apply(tmp_0, 3, ess_rfun)

n_eff_vec/S

# import the data from python and check the results
tmp_py <- as.vector(t(read.csv("tmp.csv")))

dim(tmp_py) <- c(length(tmp_py), 1)
class(tmp_py) <- "matrix"

tmp_0 <- llmatrix_to_array(tmp_py, chain_id) # from matrix to 1000 * 4 * 3020 array

length(dim(tmp_0)) == 3

S <- prod(dim(tmp_0)[1:2]) 
 
n_eff_vec <- apply(tmp_0, 3, ess_rfun)

n_eff_vec/S 

# the results is the same as in python


llmatrix_to_array <- function(x, chain_id) {
  stopifnot(is.matrix(x), all(chain_id == as.integer(chain_id)))

  lldim <- dim(x)
  n_chain <- length(unique(chain_id))
  chain_id <- as.integer(chain_id)
  chain_counts <- as.numeric(table(chain_id))

  if (length(chain_id) != lldim[1]) {
    stop("Number of rows in matrix not equal to length(chain_id).",
         call. = FALSE)
  } else if (any(chain_counts != chain_counts[1])) {
    stop("Not all chains have same number of iterations.",
         call. = FALSE)
  } else if (max(chain_id) != n_chain) {
    stop("max(chain_id) not equal to the number of chains.",
         call. = FALSE)
  }

  n_iter <- lldim[1] / n_chain
  n_obs <- lldim[2]
  a <- array(data = NA, dim = c(n_iter, n_chain, n_obs))
  for (c in seq_len(n_chain)) {
    a[, c, ] <- x[chain_id == c, , drop = FALSE]
  }
  return(a)
}

ess_rfun <- function(sims) {
  # Compute the effective sample size for samples of several chains
  # for one parameter; see the C++ code of function
  # effective_sample_size in chains.cpp
  #
  # Args:
  #   sims: a 2-d array _without_ warmup samples (# iter * # chains)
  #
  if (is.vector(sims)) dim(sims) <- c(length(sims), 1)
  chains <- ncol(sims)
  n_samples <- nrow(sims)
  acov <- lapply(1:chains, FUN = function(i) autocovariance(sims[,i]))
  acov <- do.call(cbind, acov)
  chain_mean <- colMeans(sims)
  mean_var <- mean(acov[1,]) * n_samples / (n_samples - 1)
  var_plus <- mean_var * (n_samples - 1) / n_samples
  if (chains > 1)
    var_plus <- var_plus + var(chain_mean)
  # Geyer's initial positive sequence
  rho_hat_t <- rep.int(0, n_samples)
  t <- 0
  rho_hat_even <- 1
  rho_hat_t[t + 1] <- rho_hat_even
  rho_hat_odd <- 1 - (mean_var - mean(acov[t + 2, ])) / var_plus
  rho_hat_t[t + 2] <- rho_hat_odd
  while (t < nrow(acov) - 5 && !is.nan(rho_hat_even + rho_hat_odd) &&
         (rho_hat_even + rho_hat_odd > 0)) {
    t <- t + 2
    rho_hat_even = 1 - (mean_var - mean(acov[t + 1, ])) / var_plus
    rho_hat_odd = 1 - (mean_var - mean(acov[t + 2, ])) / var_plus
    if ((rho_hat_even + rho_hat_odd) >= 0) {
      rho_hat_t[t + 1] <- rho_hat_even
      rho_hat_t[t + 2] <- rho_hat_odd
    }
  }
  max_t <- t
  # this is used in the improved estimate
  if (rho_hat_even>0)
      rho_hat_t[max_t + 1] <- rho_hat_even

  # Geyer's initial monotone sequence
  t <- 0
  while (t <= max_t - 4) {
    t <- t + 2
    if (rho_hat_t[t + 1] + rho_hat_t[t + 2] >
        rho_hat_t[t - 1] + rho_hat_t[t]) {
      rho_hat_t[t + 1] = (rho_hat_t[t - 1] + rho_hat_t[t]) / 2;
      rho_hat_t[t + 2] = rho_hat_t[t + 1];
    }
  }
  ess <- chains * n_samples
  # Geyer's truncated estimate
  # tau_hat <- -1 + 2 * sum(rho_hat_t[1:max_t])
  # Improved estimate reduces variance in antithetic case
  tau_hat <- -1 + 2 * sum(rho_hat_t[1:max_t]) + rho_hat_t[max_t+1]
  # Safety check for negative values and with max ess equal to ess*log10(ess)
  tau_hat <- max(tau_hat, 1/log10(ess))
  ess <- ess / tau_hat
  ess
}


autocovariance <- function(y) {
  # Compute autocovariance estimates for every lag for the specified
  # input sequence using a fast Fourier transform approach.
  N <- length(y)
  M <- fft_next_good_size(N)
  Mt2 <- 2 * M
  yc <- y - mean(y)
  yc <- c(yc, rep.int(0, Mt2-N))
  transform <- stats::fft(yc)
  ac <- stats::fft(Conj(transform) * transform, inverse = TRUE)
  # use "biased" estimate as recommended by Geyer (1992)
  ac <- Re(ac)[1:N] / (N^2 * 2)
  ac
}

fft_next_good_size <- function(N) {
  # Find the optimal next size for the FFT so that
  # a minimum number of zeros are padded.
  if (N <= 2)
    return(2)
  while (TRUE) {
    m = N
    while ((m %% 2) == 0) m = m / 2
    while ((m %% 3) == 0) m = m / 3
    while ((m %% 5) == 0) m = m / 5
    if (m <= 1)
      return(N)
    N = N + 1
  }
}
```

```{r}
loo(llfun_logistic, draws = parameter_draws_1, data = stan_df_1, r_eff = r_eff)
```

```{r}
start.time <- Sys.time()
# subsampling
set.seed(4711)
loo_ss_1 <-
  loo_subsample(
    llfun_logistic,
    observations = 100, # take a subsample of size 100
    cores = 2,
    # these next objects were computed above
    r_eff = r_eff, 
    draws = parameter_draws_1,
    data = stan_df_1
  )
time_loo_ss_1 <- Sys.time() - start.time
print(paste("Time taken: ", time_loo_ss_1, "secs"))
loo_ss_1
```

```{r}
start.time <- Sys.time()
# subsampling
set.seed(4711)
loo_ss_2 <-
  loo_subsample(
    llfun_logistic,
    observations = 100, # take a subsample of size 100
    cores = 2,
    # these next objects were computed above
    loo_approximation = 'tis',
    r_eff = r_eff, 
    draws = parameter_draws_1,
    data = stan_df_1
  )
time_loo_ss_2 <- Sys.time() - start.time
print(paste("Time taken: ", time_loo_ss_2, "secs"))
loo_ss_2
```

```{r}
start.time <- Sys.time()
set.seed(4711)
loo_1 <- loo(llfun_logistic,
    cores = 4,
    # these next objects were computed above
    r_eff = r_eff, 
    draws = parameter_draws_1,
    data = stan_df_1)
time_loo_1 <- Sys.time() - start.time
print(paste("Time taken: ", time_loo_1, "secs"))
loo_1
```
Comparing `loo_ss_1` and `loo_1`, we can see that the main different lies in the third column `subsampling_SE`, but the first two column is almost the same. However, the executing time is much faster for the subsampling with `plpd` method, the `pld` method will be even longer.

## Dissect the functions

### Log likelihood function
Understand the log likelihood function (`llfun`) in this example. It return point-wise log-likelihood for each data point, based on the input `data_i`.  Note that log likelihood function is different from the model, though the likelihood function is essential for MCMC in most models.

``` {r}
# used for draws argument to loo_i
parameter_draws_1 <- extract(fit_1)$beta

# used for data argument to loo_i
stan_df_1 <- as.data.frame(standata)

i <- 1
data_i <- stan_df_1[i, ]    # must be a dataframe
draws <- parameter_draws_1  # 4000 * 3
x_i <- as.matrix(data_i[, which(grepl(colnames(data_i), pattern = "X")), drop=FALSE])  # get the parameters 1*3
logit_pred <- draws %*% t(x_i) # matrix multiplication 4000 * 3 %*% 3 * 1
tmp <- dbinom(x = data_i$y, size = 1, prob = 1/(1 + exp(-logit_pred)), log = log)
```

### Subsampling step-by-step

#### Step 1: Preparing the inputs

```{r prepare inputs}
draws <- parameter_draws_1  # 4000 * 3
data <- stan_df_1
llfun <- llfun_logistic
N <- dim(data)[1]

estimator <- "diff_srs"
loo_approximation <- 'plpd'

observations <- 100
```

#### Step 2: get the point estimate

This is part of the `loo_approximation` in the `loo_subsample.R`. There are multiple ways to estimate these values, and the default is `plpd`.

* `tis` or `sis`: returns the `loo_epld` using `loo.function()` (i.e., no approximation at all)
* `lpd`: returns results of `compute_lpds`;
* `plpd`: returns results of `compute_lpds`, with an addition input of `point_est`;
* others: approximation methods.

Here we first check how the `point_est` is computed: first calculate the mean of each columns (i.e., the mean of posterior of each parameter), then convert it to a matrix (dim: 3x1 ), and then transpose it to a 1X3 matrix. Thus point estimate basically using the mean of posterior. 

This step is computing the $\hat{\theta}$ in the approximating the $\tilde{\pi} \propto -\text{log} p(y_i | \hat{\theta})$ (see section 2.5 in Magnusson et al. 2019).

Thus the `point_est` mean point estimation, i.e., means value, not point-wise estimation.

```{r pointwise estimate}
# here we replace the function .compute_point_estimate.matrix, which basically compute the means of parameters and transpose
tmp_compute_point_estimate <- function(draws) {
  t(as.matrix(colMeans(draws))) 
}

point_est <- tmp_compute_point_estimate(draws)
```

#### Step 3: Get the `elpd_loo_approx`

Here we start to use the `point_est` to estimate the `epld_loo_approx`. Basically, we replace the `draws` argument with `point_est` so that we only need three thetas for all data.

Essentially, it is a for loop, loop through the N data `llfun(data_i = data[i, , drop=FALSE], draws = draws)`, here only the mean of thetas are used to calculate the log-likelihood for each data point. After that, binding all the log-likelihood as a vector and calculate their `logMeanExp`. The question is: if we use the mean of thetas there, what's the difference between this version of loo_cv and DIC?

`elpd_loo_approx` is a vector of the same length as the data (here: 3020)

```{r elpd_loo_approx}
##  elpd_loo_approx <- elpd_loo_approximation ()...
# draws <- .thin_draws(draws, loo_approximation_draws)

# here we define compute_lpds and related function (lpd_i, logMeanExp) so that we can 
# reproduce the elpd_loo_approximation part, which returns a vector of lpds

# https://github.com/stan-dev/loo/blob/e197aa7c5ac56881ad67dae3f90479af96d83c0a/R/helpers.R#L13
logMeanExp <- function(x) {
  logS <- log(length(x))
  matrixStats::logSumExp(x) - logS
}

lpd_i <- function(i, llfun, data, draws) {
  ll_i <- llfun(data_i = data[i,, drop=FALSE], draws = draws)
  ll_i <- as.vector(ll_i)
  lpd_i <- logMeanExp(ll_i)
  lpd_i
}

compute_lpds <- function(N, data, draws, llfun, cores) {
  if (cores == 1) {
    lpds <- lapply(X = seq_len(N), FUN = lpd_i, llfun, data, draws)
  } else {
    if (.Platform$OS.type != "windows") {
      lpds <- parallel::mclapply(X = seq_len(N), mc.cores = cores, FUN = lpd_i, llfun, data, draws)
    } else {
      cl <- makePSOCKcluster(cores)
      on.exit(stopCluster(cl))
      lpds <- parLapply(cl, X = seq_len(N), fun = lpd_i, llfun, data, draws)
    }
  }
  
  unlist(lpds)
}

elpd_loo_approx <- compute_lpds(N, data, point_est, llfun_logistic, cores=1)

elpd_loo_approximation <- elpd_loo_approx
```

#### Step 4: get subsample_idxs

Here we only use the default approach `diff_srs`.

`diff_srs` use the simple random sampling without replacement (SRS), which basically randomly choose a subset of data. In this approach, the subset index was generated from ordering a uniform distribution with the same length of the `epld_loo_approx`, and then select the first subset with length of subsample size (which is defined by observation).

It's different from the `hh_pps` approach, with use the proportion to sample the subset. However, the advantage of `srs` is that it can be used for model comparison.

Note that `idxs` has two columns, the first column is `idx`, the second one is `m_i`, which is `1` for all.

```{r subsample_idxs}
# understand order()
set.seed(123)
tmp2 <- stats::runif(10)
order(tmp2)
tmp2[order(tmp2)]
#

subsample_idxs <- function(estimator, elpd_loo_approximation, observations) {
  if (estimator == "hh_pps") {
    pi_values <- pps_elpd_loo_approximation_to_pis(elpd_loo_approximation)
    idxs_df <- pps_sample(observations, pis = pi_values)
  }

  if (estimator == "diff_srs" | estimator == "srs") {
    if (observations > length(elpd_loo_approximation)) {
      stop("'observations' is larger than the total sample size in 'data'.", call. = FALSE)
    }
    idx <- 1:length(elpd_loo_approximation)
    # order function here is not the real ranking of data, but how to get those data so that the new a[order(a)] is ascending.
    idx_m <- idx[order(stats::runif(length(elpd_loo_approximation)))][1:observations]
    idx_m <- idx_m[order(idx_m)]
    idxs_df <- data.frame(idx=as.integer(idx_m), m_i=1L)
  }
  # assert_subsample_idxs(x = idxs_df)
  idxs_df
}

idxs <- subsample_idxs(
        estimator = "diff_srs", # here the default is simple random sampling (srs), i.e. randomly sub-sample
        elpd_loo_approximation = elpd_loo_approx,
        observations = observations)
```

#### Step 5: Get the `loo_obj`
Here we will use sub set of data, subset of `r_eff`, and all of posterior (draws) for the `loo_obj`. Note that the result already include output of `loo`.

The differences between the `loo_obj` and previous results of `loo()` are the data and `r_eff`. Thus the result are quite different. we can compare them here.

```{r get loo_obj}
data_subsample <- data[idxs$idx,, drop = FALSE]

if (length(r_eff) > 1) {
        r_eff <- r_eff[idxs$idx]
}

loo_obj <- loo.function(
        x = llfun_logistic,
        data = data_subsample,
        draws = draws,
        r_eff = r_eff,
        #save_psis = save_psis,
        #cores = cores
      )
```

```{r}
loo_obj
```
```{r}
loo_1
```
#### Step 6: get the `loo_obj_ss`

This part is the most crucial one, in which the core function is `psis_loo_ss_object`.

The `psis_loo_ss_object` in turn include the most important function `loo_subsample_estimation_diff_srs`, which is important because the `diff_srs` is applied here.

If we skip all the code that are used for checking or asserting, then, after `loo`, the default subsampling method boil downs to two import functions: `srs_diff_est()` and `srs_est()`.

`srs_diff_est()` calculate the `elpd_loo`'s estimate, SE, and subsampling SE, takes three input: 

* `y_approx`: the elpd_loo_approx;
* `y`: the `elpd_loo` from `loo()` function;
* `y_idx`: the subsample index. 

For `srs_diff_est()`, it will first get the length of all `elpd_loo_approx` (N) and subsample length (m), and used the index to extract `epld_loo_approx` that corresponding the subsample. The formula is from Magnusson et al. (2020). More specifically, formula (7), (8), (9).

Here is the formula (7), $elpd_{loo}$:

$$\widehat{elpd}_{diff, loo} = \sum_{i = 1}^{n}\tilde{\pi}_{i} + \frac{n}{m} \sum_{j \in S} (\pi_j - \tilde{\pi}_j)$$

Formula (8), i.e., variance of subsampling:

$$V(\widehat{elpd}_{diff, loo}) = n^2 (1 - \frac{m}{n})\frac{s_e^2}{m})$$


where $e_j = \pi_j - \tilde{\pi}_j$ and $s_e^2 = \frac{1}{m-1} \sum_j^m (e_j - \bar{e})^2$ and $\bar{e} = \frac{1}{m} \sum_j^m e_j$. In the code, $s_e^2$ was calculated by $s_e^2 = \frac{1}{m} \sum_j^m (e_j - \bar{e})^2$, thus can be short as $var(e_j)$

Formula 9, the variability of $elpd_{loo}$:

$$\hat{\sigma}_{diff, loo}^2 = \sum_{i = 1}^{n} \tilde{\pi}_i^2 + \frac{n}{m} \sum_{j \in S} (\pi_j^2 - \tilde{\pi}_j^2) + \frac {1}{n} \left[ \left(\frac{n}{m} \sum_{j \in S} (\pi_j - \tilde{\pi}_j \right)^2 - V(\widehat{elpd}_{diff, loo}) \right] + \frac {1}{n} \left[ 2 \left(\sum_{i=1}^{n}\pi_i \right) \widehat{elpd}_{diff, loo} - \left( \sum_{i=1}^{n}\pi_i \right)^2 \right]$$ 

In the `r` code below:

* `e_i`: $e_j = \pi_j - \tilde{\pi}_j$
* `t_pi_tilde`: $\sum_{i=1}^{n}\tilde{\pi}_i$
* `t_pi2_tilde`: $\sum_{i=1}^{n}\tilde{\pi}_i^2$
* `t_e`: $\frac{n}{m}\sum e_j = \frac{n}{m}\sum (\pi_j - \tilde{\pi}_j)$
* `t_hat_epsilon`: $\frac{n}{m}\sum (\pi_j^2 - \tilde{\pi}_j^2)$

```{r}
# The forth layer for estimation: srs_diff_est and srs_est
srs_diff_est <- function(y_approx, y, y_idx) {

  N <- length(y_approx)
  m <- length(y)
  y_approx_m <- y_approx[y_idx]

  e_i <- y - y_approx_m
  t_pi_tilde <- sum(y_approx)
  t_pi2_tilde <- sum(y_approx^2)
  t_e <- N * mean(e_i)
  t_hat_epsilon <- N * mean(y^2 - y_approx_m^2)

  est_list <- list(m = length(y), N = N)
  est_list$y_hat <- t_pi_tilde + t_e
  est_list$v_y_hat <- N^2 * (1 - m / N) * var(e_i) / m
  est_list$hat_v_y <- (t_pi2_tilde + t_hat_epsilon) - # a (has been checked)
    (1/N) * (t_e^2 - est_list$v_y_hat + 2 * t_pi_tilde * est_list$y_hat - t_pi_tilde^2) # b
  est_list
}

```

update `p_loo` for subsampling.
How `p_loo` is calculated? not find the equations in papers yet.

`srs_est()` calculate `p_loo`'s estimate, SE, and subsampling SE has two inputs: 

* `y`:  `p_loo` from `loo()` function, i.e., `x$pointwise[, "p_loo"]`; 
* `y_approx`: the elpd_loo_approx, `x$loo_subsampling$elpd_loo_approx`.

```{r}
srs_est <- function(y, y_approx) {
  checkmate::assert_numeric(y)
  checkmate::assert_numeric(y_approx, min.len = length(y))
  N <- length(y_approx)
  m <- length(y)
  est_list <- list(m = m)
  est_list$y_hat <- N * mean(y)
  est_list$v_y_hat <- N^2 * (1-m/N) * var(y)/m
  est_list$hat_v_y <- N * var(y)

  est_list
}
```


$$e_i = elpd_{loo-m} - elpd_{loo-approx-m} $$

$$\tilde{t_{\pi}} = \sum(elpd_{loo-approx})$$
$$\tilde{t_{\pi^2}} = \sum((elpd_{loo-approx})^2) $$
$$t_e = N * mean (e_i)$$
$$\hat{t_{\epsilon}} = N * mean(elpd_{loo-m} - elpd_{loo-approx-m}^2)$$

This is the final $elpd_{loo}$:
$$ \hat{y} = \tilde {t_{\pi}} + t_e = \sum (elpd_{loo-approx}) + N*mean(e_i)$$
This the final SE of $elpd_{loo}$:
$$Var{\hat{y} = N^2 * (1 - m / N) * var(e_i) / m }$$
This the final subsample SE of $elpd_{loo}$:
$$\hat{v_{y}} = (\tilde {t_{\pi^2}} + \hat{t_{\epsilon}}) - (1/N) * (t_e^2 - \hat{v_y} + 2 * \tilde {t_{\pi}}  * \hat {y} - \tilde {t_{\pi}}^2)$$
from `loo_obj` to `loo_ss` object:

(1) Add subsampling variables to the `loo_obj`'s pointwise and formed new pointwise variable:

* `idxs`, the index matrix of subsample, 
* a subset of `elpd_loo_approx` selected by `idxs`.

(2) create a new list `loo_subsampling`, which records the information related to subsampling

* `elpd_loo_approx`: All `elpd_loo_approx` from previous step 
* `loo_approxmiation`: methods fro the `elpd_loo_approx`
* `loo_approximation_draws`
* `estimator`
* `.llfun`
* `.llgrad`
* `data_dim`:
* `ndraws`: number of all draws before subsampling

(3) update the `estimates` by `loo_subsample_estimation_*`, which include six items:

* `Estimate`, `SE`, and `subsampling SE` of `elpd_loo`, which estimated by `srs_diff_est()`
* `Estimate`, `SE`, and `subsampling SE` of `p_loo`, estimated by `srs_est()`


(4) update the values using `update_psis_loo_ss_estimates`

* get the `looic` 
* update `elpd_loo`, `p_loo`, `looic`, `se_elpd_loo`, `se_p_loo`, `se_looic` of `loo_obj`.

```{r get loo_obj_ss}
x_tmp <- loo_obj
## psis_loo_ss_object's core fucntion:
x_tmp$pointwise <- add_subsampling_vars_to_pointwise(pointwise = x_tmp$pointwise, idxs=idxs, elpd_loo_approx= elpd_loo_approx)

x_tmp$loo_subsampling <- list()
x_tmp$loo_subsampling$elpd_loo_approx <- elpd_loo_approx
x_tmp$loo_subsampling$loo_approximation <- loo_approximation
x_tmp$loo_subsampling["loo_approximation_draws"] <- list(NULL)
x_tmp$loo_subsampling$estimator <- estimator
x_tmp$loo_subsampling$.llfun <- llfun
x_tmp$loo_subsampling[".llgrad"] <- list(NULL)
x_tmp$loo_subsampling[".llhess"] <- list(NULL)
x_tmp$loo_subsampling$data_dim <- dim(data)
x_tmp$loo_subsampling$ndraws <- .ndraws(draws)

## core function of srs_diff_est
y_approx_tmp <- x_tmp$loo_subsampling$elpd_loo_approx
y_tmp <- x_tmp$pointwise[, 'elpd_loo']
y_idx_tmp <- x_tmp$pointwise[, "idx"]

N <- length(y_approx_tmp)
m <- length(y_tmp)
y_approx_m <- y_approx_tmp[y_idx_tmp]

e_i <- y_tmp - y_approx_m
t_pi_tilde <- sum(y_approx_tmp)
t_pi2_tilde <- sum(y_approx_tmp^2)
t_e <- N * mean(e_i)
t_hat_epsilon <- N * mean(y_tmp^2 - y_approx_m^2)

est_list <- list(m = length(y_tmp), N = N)
est_list$y_hat <- t_pi_tilde + t_e
est_list$v_y_hat <- N^2 * (1 - m / N) * var(e_i) / m
est_list$hat_v_y <- (t_pi2_tilde + t_hat_epsilon) - # a (has been checked)
(1/N) * (t_e^2 - est_list$v_y_hat + 2 * t_pi_tilde * est_list$y_hat - t_pi_tilde^2) # b
elpd_loo_est <- est_list

# the most out layer
loo_ss <- psis_loo_ss_object(x = loo_obj,
                         idxs = idxs,
                         elpd_loo_approx = elpd_loo_approx,
                         loo_approximation = 'plpd',
                         loo_approximation_draws = NULL,
                         estimator = "diff_srs",
                         .llfun = llfun_logistic,
                         .llgrad = NULL,
                         .llhess = NULL,
                         data_dim = dim(data),
                         ndraws = .ndraws(draws))

# The second layer function
psis_loo_ss_object <- function(x,
                               idxs,
                               elpd_loo_approx,
                               loo_approximation, 
                               loo_approximation_draws,
                               estimator,
                               .llfun, .llgrad, .llhess,
                               data_dim, ndraws) {
  # Assertions
  checkmate::assert_class(x, "psis_loo")
  # assert_subsample_idxs(idxs)
  checkmate::assert_numeric(elpd_loo_approx, any.missing = FALSE)
  checkmate::assert_choice(loo_approximation, loo_approximation_choices())
  checkmate::assert_int(loo_approximation_draws, null.ok = TRUE)
  checkmate::assert_choice(estimator, estimator_choices())
  checkmate::assert_function(.llfun, args = c("data_i", "draws"), ordered = TRUE)
  checkmate::assert_function(.llgrad, args = c("data_i", "draws"), ordered = TRUE, null.ok = TRUE)
  checkmate::assert_function(.llhess, args = c("data_i", "draws"), ordered = TRUE, null.ok = TRUE)
  checkmate::assert_integer(data_dim, len = 2, lower = 1, any.missing = FALSE)
  checkmate::assert_int(ndraws, lower = 1)

  # Construct object
  class(x) <- c("psis_loo_ss", class(x))
  x$pointwise <- add_subsampling_vars_to_pointwise(pointwise = x$pointwise, idxs, elpd_loo_approx)
  x$estimates <- cbind(x$estimates, matrix(0, nrow = nrow(x$estimates)))
  colnames(x$estimates)[ncol(x$estimates)] <- "subsampling SE"

  x$loo_subsampling <- list()
  x$loo_subsampling$elpd_loo_approx <- elpd_loo_approx
  x$loo_subsampling$loo_approximation <- loo_approximation
  x$loo_subsampling["loo_approximation_draws"] <- list(loo_approximation_draws)
  x$loo_subsampling$estimator <- estimator
  x$loo_subsampling$.llfun <- .llfun
  x$loo_subsampling[".llgrad"] <- list(.llgrad)
  x$loo_subsampling[".llhess"] <- list(.llhess)
  x$loo_subsampling$data_dim <- data_dim
  x$loo_subsampling$ndraws <- ndraws

  # Compute estimates
  if (estimator == "hh_pps") {
    x <- loo_subsample_estimation_hh(x)
  } else if (estimator == "diff_srs") {
    x <- loo_subsample_estimation_diff_srs(x)
  } else if (estimator == "srs") {
    x <- loo_subsample_estimation_srs(x)
  } else {
    stop("No correct estimator used.")
  }
  assert_psis_loo_ss(x)
  x
}

# The third layer functions
add_subsampling_vars_to_pointwise <- function(pointwise, idxs, elpd_loo_approx) {
  ## This function added three columns: idx, m_i, elpd_loo_approx
  checkmate::assert_matrix(pointwise,
                           any.missing = FALSE,
                           min.cols = 5)
  checkmate::assert_names(colnames(pointwise), identical.to = c("elpd_loo","mcse_elpd_loo","p_loo","looic", "influence_pareto_k"))
  # assert_subsample_idxs(idxs)
  checkmate::assert_numeric(elpd_loo_approx)

  pw <- cbind(as.data.frame(pointwise), idxs) # idxs have two columns: idx and m_i
  pw$elpd_loo_approx <- elpd_loo_approx[idxs$idx]
  pw <- as.matrix(pw)
  rownames(pw) <- NULL
  #assert_subsampling_pointwise(pw)
  pw
}

assert_psis_loo_ss <- function(x) {
  checkmate::assert_class(x, "psis_loo_ss")
  checkmate::assert_names(names(x), must.include = c("estimates", "pointwise", "diagnostics", "psis_object", "loo_subsampling"))
  checkmate::assert_names(rownames(x$estimates), must.include = c("elpd_loo", "p_loo", "looic"))
  checkmate::assert_names(colnames(x$estimates), must.include = c("Estimate", "SE", "subsampling SE"))
  assert_subsampling_pointwise(x$pointwise)
  checkmate::assert_names(names(x$loo_subsampling),
                          must.include = c("elpd_loo_approx",
                                           "loo_approximation", "loo_approximation_draws",
                                           "estimator",
                                           "data_dim", "ndraws"))
  checkmate::assert_numeric(x$loo_subsampling$elpd_loo_approx, any.missing = FALSE, len = x$loo_subsampling$data_dim[1])
  checkmate::assert_choice(x$loo_subsampling$loo_approximation, choices = loo_approximation_choices(api = FALSE))
  checkmate::assert_int(x$loo_subsampling$loo_approximation_draws, null.ok = TRUE)
  checkmate::assert_choice(x$loo_subsampling$estimator, choices = estimator_choices())
  checkmate::assert_integer(x$loo_subsampling$data_dim, any.missing = TRUE, len = 2)
  checkmate::assert_int(x$loo_subsampling$data_dim[1], na.ok = FALSE)
  checkmate::assert_integer(x$loo_subsampling$ndraws, len = 1, any.missing = TRUE)
  x
}

loo_subsample_estimation_diff_srs <- function(x) {
  checkmate::assert_class(x, "psis_loo_ss")

  elpd_loo_est <- srs_diff_est(y_approx = x$loo_subsampling$elpd_loo_approx, y = x$pointwise[, "elpd_loo"], y_idx = x$pointwise[, "idx"])
  x$estimates["elpd_loo", "Estimate"] <- elpd_loo_est$y_hat
  x$estimates["elpd_loo", "SE"] <- sqrt(elpd_loo_est$hat_v_y)
  x$estimates["elpd_loo", "subsampling SE"] <- sqrt(elpd_loo_est$v_y_hat)

  p_loo_est <- srs_est(y = x$pointwise[, "p_loo"], y_approx = x$loo_subsampling$elpd_loo_approx)
  x$estimates["p_loo", "Estimate"] <- p_loo_est$y_hat
  x$estimates["p_loo", "SE"] <- sqrt(p_loo_est$hat_v_y)
  x$estimates["p_loo", "subsampling SE"] <- sqrt(p_loo_est$v_y_hat)

  update_psis_loo_ss_estimates(x)
}

# The forth layer for esetimation: srs_diff_est and srs_est
srs_diff_est <- function(y_approx, y, y_idx) {
  checkmate::assert_numeric(y_approx)
  checkmate::assert_numeric(y, max.len = length(y_approx))
  checkmate::assert_integerish(y_idx, len = length(y))

  N <- length(y_approx)
  m <- length(y)
  y_approx_m <- y_approx[y_idx]

  e_i <- y - y_approx_m
  t_pi_tilde <- sum(y_approx)
  t_pi2_tilde <- sum(y_approx^2)
  t_e <- N * mean(e_i)
  t_hat_epsilon <- N * mean(y^2 - y_approx_m^2)

  est_list <- list(m = length(y), N = N)
  est_list$y_hat <- t_pi_tilde + t_e
  est_list$v_y_hat <- N^2 * (1 - m / N) * var(e_i) / m
  est_list$hat_v_y <- (t_pi2_tilde + t_hat_epsilon) - # a (has been checked)
    (1/N) * (t_e^2 - est_list$v_y_hat + 2 * t_pi_tilde * est_list$y_hat - t_pi_tilde^2) # b
  est_list
}

srs_est <- function(y, y_approx) {
  checkmate::assert_numeric(y)
  checkmate::assert_numeric(y_approx, min.len = length(y))
  N <- length(y_approx)
  m <- length(y)
  est_list <- list(m = m)
  est_list$y_hat <- N * mean(y)
  est_list$v_y_hat <- N^2 * (1-m/N) * var(y)/m
  est_list$hat_v_y <- N * var(y)

  est_list
}

# the forth layer function: update
update_psis_loo_ss_estimates <- function(x) {
  checkmate::assert_class(x, "psis_loo_ss")

  x$estimates["looic", "Estimate"] <- (-2) * x$estimates["elpd_loo", "Estimate"]
  x$estimates["looic", "SE"] <- 2 * x$estimates["elpd_loo", "SE"]
  x$estimates["looic", "subsampling SE"] <- 2 * x$estimates["elpd_loo", "subsampling SE"]

  x$elpd_loo <- x$estimates["elpd_loo", "Estimate"]
  x$p_loo <- x$estimates["p_loo", "Estimate"]
  x$looic <- x$estimates["looic", "Estimate"]
  x$se_elpd_loo <- x$estimates["elpd_loo", "SE"]
  x$se_p_loo <- x$estimates["p_loo", "SE"]
  x$se_looic <- x$estimates["looic", "SE"]

  x
}

assert_subsampling_pointwise <- function(x) {
  checkmate::assert_matrix(x,
                           any.missing = FALSE,
                           ncols = 8)
  checkmate::assert_names(colnames(x), identical.to = c("elpd_loo", "mcse_elpd_loo", "p_loo", "looic", "influence_pareto_k", "idx", "m_i", "elpd_loo_approx"))
  x
}

# other utilities:
loo_approximation_choices <- function(api = TRUE) {
  lac <- c("plpd", "lpd", "waic", "waic_grad_marginal", "waic_grad", "waic_hess", "tis", "sis", "none")
  if (!api) lac <- c(lac, "psis")
  lac
}

estimator_choices <- function() {
  c("hh_pps", "diff_srs", "srs")
}


.ndraws <- function(x) {
  UseMethod(".ndraws")
}

.ndraws.matrix <- function(x) {
  nrow(x)
}

.ndraws.default <- function(x) {
  stop(".ndraws() has not been implemented for objects of class '", class(x), "'")
}

```


```{r additional subsampling}
set.seed(4711)
loo_ss_1b <-
  update(
    loo_ss_1,
    observations = 200, # subsample 200 instead of 100
    r_eff = r_eff,
    draws = parameter_draws_1,
    data = stan_df_1
  ) 
print(loo_ss_1b)
```
```{r specify subsampling method}
set.seed(4711)
loo_ss_1c <-
  loo_subsample(
    x = llfun_logistic,
    r_eff = r_eff,
    draws = parameter_draws_1,
    data = stan_df_1,
    observations = 100,
    estimator = "hh_pps", # use Hansen-Hurwitz
    loo_approximation = "lpd", # use lpd instead of plpd
    loo_approximation_draws = 100,
    cores = 2
  )
print(loo_ss_1c)
```
