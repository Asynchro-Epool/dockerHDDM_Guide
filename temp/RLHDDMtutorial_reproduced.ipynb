{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial for analyzing instrumental learning data with the HDDMrl module\n",
    "This is a tutorial for using the HDDMrl module to simultaneously estimate reinforcement learning parameters and decision parameters within a fully hierarchical bayesian estimation framework, including steps for sampling, assessing convergence, model fit, parameter recovery, and posterior predictive checks (model validation). The module uses the reinforcement learning drift diffusion model (RLDDM), a reinforcement learning model that replaces the standard “softmax” choice function with a drift diffusion process. The softmax and drift diffusion process is equivalent for capturing choice proportions, but the DDM also takes RT distributions into account; options are provided to also only fit RL parameters without RT. The RLDDM estimates trial-by-trial drift rate as a scaled difference in expected rewards (expected reward for upper bound alternative minus expected reward for lower bound alternative). Expected rewards are updated with a delta learning rule using either a single learning rate or with separate learning rates for positive and negative prediction errors. The model also includes the standard DDM-parameters. The RLDDM is described in detail in [Pedersen, Frank & Biele (2017).](http://ski.clps.brown.edu/papers/PedersenEtAl_RLDDM.pdf) (Note this approach differs from Frank et al (2015) who used HDDM to fit instrumental learning but did not allow for simultaneous estimation of learning parameters). \n",
    "\n",
    "## OUTLINE \n",
    "\n",
    "[1. Background](#1.-Background) <br>\n",
    "[2. Installing the module](#2.-Installing-the-module) <br>\n",
    "[3. How the RLDDM works](#3.-How-the-RLDDM-works) <br>\n",
    "[4. Structuring data](#4.-Structuring-data) <br>\n",
    "[5. Running basic model](#5.-Running-basic-model) <br>\n",
    "[6. Checking results](#6.-Checking-results) <br>\n",
    "[7. Posterior predictive checks](#7.-Posterior-predictive-checks)<br>\n",
    "[8. Parameter recovery](#8.-Parameter-recovery)<br>\n",
    "[9. Separate learning rates for positive and negative prediction errors](#9.-Separate-learning-rates-for-positive-and-negative-prediction-errors)<br>\n",
    "[10. depends_on vs. split_by](#10.-depends_on-vs.-split_by)<br>\n",
    "[11. Probabilistic binary outcomes vs. normally distributed outcomes](#11.-Probabilistic-binary-outcomes-vs.-normally-distributed-outcomes)<br>\n",
    "[12. HDDMrlRegressor](#12.-HDDMrlRegressor)<br>\n",
    "[13. Regular RL without RT](#13.-Regular-RL-without-RT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Background\n",
    "Traditional RL models typically assume static decision processes (e.g. softmax), and the DDM typically assumes static decision variables (stimuli are modeled with the same drift rate across trials). The RLDDM combines dynamic decision variables from RL and dynamic choice process from DDM by assuming trial-by-trial drift rate that depends on the difference in expected rewards, which are updated on each trial by a rate of the prediction error dependent on the learning rate. The potential benefit of the RLDDM is thus to gain a better insight into decision processes in instrumental learning by also accounting for speed of decision making."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Installing the module\n",
    "The new version of HDDM (version 0.7.1) that includes the RLDDM is currently not uploaded to conda. So to install you would either have to use pip:<br>\n",
    "'pip install hddm' <br>\n",
    "OR <br>\n",
    "docker: 'pull madslupe/hddm', which runs hddm in jupyter notebook <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. How the RLDDM works\n",
    "The main idea of the RLDDM is that reward-based choices can be captured by an accumulation-to-bound process where drift rate is proportional to the difference in expected reward between options, and where expected rewards subsequently are updated in a trial-by-trial basis via reinforcement learning. <br><br>\n",
    "__drift rate on each trial depends on difference in expected rewards for the two alternatives (q_up and q_low):__ <br>\n",
    "drift rate = (q_up - q_low) * scaling <br><br>\n",
    "_where the scaling parameter describes the weight to put on the difference in q-values._<br><br>\n",
    "__expeceted reward (q) for chosen option is updated according to delta learning rule :__ <br>\n",
    "q_chosen = q_chosen + alpha * (feedback-q_chosen) <br><br>\n",
    "_where alpha weights the rate of learning on each trial._<br><br>\n",
    "So in principle all you need is the Wiener first passage time likelihood-function. The reason why HDDM is useful (and hence also HDDMrl) is that it automates the process of setting up and running your model, which tends to be very time consuming. So after structuring the data it is simple to run a model with HDDMrl. In particular it separates subjects and conditions (using the split_by-column, see next section) so that the updating process works correctly, which can be especially difficult to do for RL models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Structuring data\n",
    "The HDDMrl module was created to make it easier to model instrumental learning data with the RLDDM. If you are familiar with using HDDM it shouldn't be a big step to start using HDDMrl. Please refresh your memory by starting with the [tutorial for HDDM](http://ski.clps.brown.edu/hddm_docs/index.html) first (especially critical if you have not used HDDM at all). Running HDDMrl does require a few extra steps compared to HDDM, and because the model includes increased potential for parameter colinearity  (typically learning rate and the scaling parameter on drift rate) it is even more important to assess model fit, which will be covered below. Here are the most important steps for structuring your dataframe:\n",
    "1. Sort trials in ascending order within subject and condition, to ensure proper updating of expected rewards.\n",
    "2. Include a column called __'split_by'__ which identifies the different task conditions (__as integers__), to ensure reward updating will work properly for each condition without mixing values learned from one trial type to another. \n",
    "3. Code the response column with [stimulus-coding] (http://ski.clps.brown.edu/hddm_docs/howto.html#code-subject-responses). Although stimulus-coding and accuracy-coding often are the same in instrumental learning it is important that the upper and lower boundaries are represented by the same alternative within a condition, because expected rewards are linked to the thresholds/boundaries.\n",
    "4. __feedback__-column. This should be the reward received for the chosen option on each trial.\n",
    "5. __q_init__. Adjusting initial q-values is something that can improve model fit quite a bit. To allow the user to set their own initial values we therefore require that the dataframe includes a column called q_init. The function will set all initial q-values according to the first value in q_init. So this is not the most elegant method of allowing users to set inital value for expected rewards, but it works for now.\n",
    "\n",
    "#### Required columns in data:\n",
    "* __rt__: in seconds, same as in HDDM\n",
    "* __response__: 0 or 1. defines chosen stimulus, not accuracy.\n",
    "* __split_by__: needs to be an integer. Split_by defines conditions (trial-types) that should have the same variables (e.g. Q values) within subject: the trials need to be split by condition to ensure proper updating of expected rewards that do not bleed over into other trial-types. (e.g. if you have stimulus A and get reward you want that updated value to impact choice only for the next stimulus A trial but not necessarily the immediate trial afterwards, which may be of a different condition) \n",
    "* __subj_idx__: same as in HDDM, but even more important here because it is used to split trials\n",
    "* __feedback__: feedback on the current trial. can be any value.\n",
    "* __q_init__: used to initialize expected rewards. can be any value, but an unbiased initial value should be somewhere between the minimum and and maximum reward values (e.g. 0.5 for tasks with rewards of 0 and 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Running basic model\n",
    "To illustrate how to run the model we will use example data from the learning phase of the probabilistic selection task (PST). During the learning phase of the PST subjects choose between two  stimuli presented as Hiragana-letters (here represented as letters from the latin alphabet). There are three conditions with different probabilities of receiving reward (feedback=1) and non-reward (feedback=0). In the AB condition A is rewarded with 80% probability, B with 20%. In the CD condition C is rewarded with 70% probability and D with 30%, while in the EF condition E is rewarded with a 60% probability and F with 40%. The dataset is included in the data-folder in your installation of HDDM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/IPython/parallel.py:12: ShimWarning: The `IPython.parallel` package has been deprecated since IPython 4.0. You should import from ipyparallel instead.\n",
      "  warn(\"The `IPython.parallel` package has been deprecated since IPython 4.0. \"\n"
     ]
    }
   ],
   "source": [
    "import os, time, csv, datetime\n",
    "\n",
    "#import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hddm\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pymc\n",
    "import kabuki\n",
    "sns.set(style=\"white\")\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subj_idx</th>\n",
       "      <th>response</th>\n",
       "      <th>cond</th>\n",
       "      <th>rt</th>\n",
       "      <th>trial</th>\n",
       "      <th>split_by</th>\n",
       "      <th>feedback</th>\n",
       "      <th>q_init</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CD</td>\n",
       "      <td>1.255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>EF</td>\n",
       "      <td>0.778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AB</td>\n",
       "      <td>0.647</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AB</td>\n",
       "      <td>0.750</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>EF</td>\n",
       "      <td>0.772</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CD</td>\n",
       "      <td>0.680</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AB</td>\n",
       "      <td>0.535</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CD</td>\n",
       "      <td>0.580</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>EF</td>\n",
       "      <td>0.461</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CD</td>\n",
       "      <td>0.869</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subj_idx  response cond     rt  trial  split_by  feedback  q_init\n",
       "0        42       0.0   CD  1.255    1.0         1       0.0     0.5\n",
       "1        42       1.0   EF  0.778    1.0         2       0.0     0.5\n",
       "2        42       1.0   AB  0.647    1.0         0       1.0     0.5\n",
       "3        42       1.0   AB  0.750    2.0         0       1.0     0.5\n",
       "4        42       0.0   EF  0.772    2.0         2       1.0     0.5\n",
       "5        42       1.0   CD  0.680    2.0         1       0.0     0.5\n",
       "6        42       1.0   AB  0.535    3.0         0       1.0     0.5\n",
       "7        42       1.0   CD  0.580    3.0         1       1.0     0.5\n",
       "8        42       0.0   EF  0.461    3.0         2       0.0     0.5\n",
       "9        42       1.0   CD  0.869    4.0         1       1.0     0.5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data. you will find this dataset in your hddm-folder under hddm/examples/rlddm_data.csv\n",
    "data = hddm.load_csv('rlddm_data.csv')\n",
    "#check structure\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns in the datafile represent: __subj_idx__ (subject id), __response__ (1=best option), __cond__ (identifies condition, but not used in model), __rt__ (in seconds), 0=worst option), __trial__ (the trial-iteration for a subject within each condition), __split_by__ (identifying condition, used for running the model), __feedback__ (whether the response given was rewarded or not), __q_init__ (the initial q-value used for the model, explained above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [-----------------100%-----------------] 1501 of 1500 complete in 157.5 sec                    mean       std      2.5q       25q        50q        75q      97.5q    mc err\n",
      "a               1.749773  0.079052  1.599324  1.696702    1.74405   1.798752   1.927646  0.003299\n",
      "a_std            0.40757  0.062705  0.304112  0.360569   0.402228   0.447183   0.549667  0.002587\n",
      "a_subj.3        2.005406  0.101298  1.815168  1.937168   2.001746   2.074915   2.222703   0.00478\n",
      "a_subj.4        1.905729  0.055083  1.802186  1.866928   1.903554   1.943739   2.013367  0.002558\n",
      "a_subj.5         1.48196   0.06794  1.352228  1.434005    1.48059   1.526155   1.621419  0.003027\n",
      "a_subj.6        2.391771  0.097553  2.204101  2.322945   2.391009   2.456902   2.586866  0.004403\n",
      "a_subj.8        2.479713  0.128581  2.252684  2.388746   2.472432   2.563727   2.750995   0.00595\n",
      "a_subj.12       1.898931  0.068991  1.770754  1.851591   1.898229   1.943441   2.037768  0.003332\n",
      "a_subj.17       1.405085   0.09501  1.204033  1.348492   1.409659    1.46747   1.582924   0.00621\n",
      "a_subj.18       1.909115  0.128269  1.683878  1.821405   1.896508   1.993083   2.179525  0.007438\n",
      "a_subj.19       2.081121  0.082325   1.92253  2.025583   2.076647   2.136354   2.240755  0.003794\n",
      "a_subj.20       1.715404  0.081307  1.566176  1.657957   1.712662   1.769522   1.884571  0.004575\n",
      "a_subj.22       1.193223  0.032694  1.131797  1.170632    1.19258   1.215592   1.257977  0.001524\n",
      "a_subj.23       1.938032  0.091733  1.768871   1.87025   1.937988   1.998109   2.126043  0.004197\n",
      "a_subj.24       1.691073  0.095626  1.522337  1.625567   1.685284   1.747034   1.897947  0.004586\n",
      "a_subj.26       2.227298  0.078111   2.07734  2.174462   2.222879    2.28049   2.393815  0.003751\n",
      "a_subj.33       1.566618  0.071027  1.436127  1.515698   1.561109   1.615294   1.708099  0.002936\n",
      "a_subj.34       1.826749    0.0885  1.660647  1.767626   1.823049   1.883231   2.014937  0.004007\n",
      "a_subj.35       1.832075  0.089767  1.665609  1.771279   1.828873   1.890663   2.020587  0.003971\n",
      "a_subj.36       1.323599  0.069436  1.204119  1.269825   1.322303    1.36915   1.465148  0.003232\n",
      "a_subj.39       1.568159  0.054959  1.465339  1.531349   1.568123    1.60327   1.683578  0.002427\n",
      "a_subj.42        1.72204  0.076064  1.582289  1.667982   1.720755   1.773454   1.876491   0.00359\n",
      "a_subj.50       1.461814  0.054212  1.365541  1.424013   1.458548   1.496687   1.577637   0.00322\n",
      "a_subj.52       2.123549  0.080065  1.976823  2.067579   2.121181   2.174709   2.283626  0.003699\n",
      "a_subj.56       1.473296  0.047004  1.382737   1.44036   1.473041   1.504442   1.576331  0.002106\n",
      "a_subj.59       1.314012  0.088179  1.154219  1.248811   1.313578   1.374024    1.49871  0.006133\n",
      "a_subj.63       1.869081  0.091345  1.693248  1.806332    1.86731   1.932931   2.053182  0.003696\n",
      "a_subj.71       1.246318  0.033635  1.178738  1.223759   1.246374   1.269743   1.309996  0.001561\n",
      "a_subj.75        0.97999  0.037796  0.914086  0.955662   0.977536   1.002819   1.063977  0.001795\n",
      "a_subj.80       2.190524  0.092646  2.013616  2.128213   2.184196   2.253174   2.377024   0.00389\n",
      "v               4.377156  0.927528  2.895452   3.70174   4.266946   4.905855   6.513976  0.069563\n",
      "v_std           3.156643   0.60969  2.211893  2.694279   3.077663   3.562618    4.54801  0.042466\n",
      "v_subj.3        6.067166  2.754949   1.28409  4.140655    5.85053   7.754646  12.167955  0.221282\n",
      "v_subj.4        0.932719  0.142219  0.666838  0.836442   0.923557   1.020781   1.225014  0.006496\n",
      "v_subj.5        5.851751  2.551912  1.973716  3.970235   5.489681   7.352449  12.021465  0.178598\n",
      "v_subj.6        5.051595  2.496962  1.395523  3.181905   4.713017   6.558382  11.414024  0.210076\n",
      "v_subj.8        3.898687  1.755446  1.860698  2.697275   3.397466    4.63568    8.44547  0.143874\n",
      "v_subj.12       2.092709  1.042043  1.414022  1.698185    1.83902   2.028441   5.856896  0.100111\n",
      "v_subj.17       7.192329   2.16839  4.020586  5.660944   6.792196   8.191917  12.808635  0.158516\n",
      "v_subj.18       6.964815  2.163897  3.837944  5.361791   6.580462   8.316556  12.421164   0.17706\n",
      "v_subj.19      12.027963  2.068201  8.658582  10.53313  11.777865  13.287829   16.58909  0.156686\n",
      "v_subj.20       5.035845  1.259602  3.123756  4.112527   4.892963   5.734807   7.982403  0.105591\n",
      "v_subj.22       2.233966  0.294905  1.680471  2.027379   2.226518   2.438359   2.840626   0.01267\n",
      "v_subj.23       2.800705  2.079513  0.934168   1.42013    1.86119   3.599204   8.255085  0.184155\n",
      "v_subj.24       5.191266  0.702592   3.80396  4.727617   5.175433   5.658292   6.590198  0.027894\n",
      "v_subj.26       0.543389  0.505993  0.222101  0.393649   0.478862   0.563054   0.828615  0.041151\n",
      "v_subj.33       3.057404  2.420117  0.223431  1.236425   2.362185   4.279299   9.428666  0.161364\n",
      "v_subj.34       4.663603  2.487553  1.134313  2.783954   4.156007    6.17569    10.9036  0.174446\n",
      "v_subj.35       3.431909  2.420545   1.11517  1.846465   2.606722   4.223985  10.540951  0.213385\n",
      "v_subj.36        4.33395   2.63145  1.481823  2.403823   3.604094   5.588344  11.366435  0.220205\n",
      "v_subj.39       2.911673  2.326105  0.443762  1.132985   2.106353   4.124919    8.53848  0.167126\n",
      "v_subj.42       5.021452  1.934909  2.306185  3.730022   4.672114   5.904619  10.008061  0.170645\n",
      "v_subj.50       6.307729  2.293951  2.806037  4.699258   5.894142   7.480485  12.063025  0.194223\n",
      "v_subj.52       3.932194   2.21866  1.259353  2.231625   3.385827   5.109984   9.465198  0.197397\n",
      "v_subj.56       2.459156  2.270591  0.267416  0.721215   1.484746   3.719006   8.136748  0.179623\n",
      "v_subj.59      11.101322  1.947392  7.919423  9.835329  10.873423  12.166345  15.385103  0.141254\n",
      "v_subj.63       2.354847  1.601347  0.886009  1.484778   1.837698   2.551639   6.963465  0.134489\n",
      "v_subj.71       2.263136  1.855318  0.667831  1.138915   1.595637   2.628684   7.999806  0.162412\n",
      "v_subj.75        3.82518  0.566393  2.778445  3.456284    3.81889    4.19479   5.063591  0.028113\n",
      "v_subj.80       4.209873  2.399342  0.977957  2.265083   3.841613   5.619553    9.91104   0.18573\n",
      "t               0.433243  0.043165   0.35242  0.403139    0.43107   0.461363   0.523344  0.001998\n",
      "t_std           0.234179  0.044498  0.168174  0.202482   0.227978   0.258652    0.34126  0.002361\n",
      "t_subj.3        1.063989  0.026964  1.000604  1.047891   1.067689   1.083537   1.109383  0.001149\n",
      "t_subj.4        0.525478  0.018103  0.487779  0.513045   0.526448   0.538632   0.559373  0.000848\n",
      "t_subj.5        0.529265  0.013609  0.500141    0.5208   0.529753   0.538961   0.554758   0.00058\n",
      "t_subj.6        0.398823  0.030946  0.334522  0.379124   0.399577   0.420644   0.457316  0.001426\n",
      "t_subj.8        0.664276  0.042654  0.569978  0.640227   0.668574    0.69391   0.738441  0.001935\n",
      "t_subj.12       0.409306  0.013932  0.379108  0.400658   0.409892   0.419088   0.436393  0.000629\n",
      "t_subj.17        0.50099  0.022506  0.466451   0.48854   0.498943   0.506489   0.568251  0.001817\n",
      "t_subj.18       0.436329  0.028835  0.368506  0.421188   0.442028   0.456123   0.480916  0.001692\n",
      "t_subj.19       0.419683  0.014601  0.389956   0.41026   0.420379   0.429993   0.446576  0.000627\n",
      "t_subj.20       0.515831  0.012607  0.488078  0.507682   0.516798   0.524745   0.537601  0.000626\n",
      "t_subj.22       0.335261   0.00496   0.32466  0.332217   0.335531   0.338597   0.344849  0.000233\n",
      "t_subj.23       0.480727  0.023137  0.427783  0.466035   0.483063   0.496741   0.520867  0.000945\n",
      "t_subj.24       0.453391  0.013535  0.422944  0.446274   0.454748   0.463078   0.475622   0.00061\n",
      "t_subj.26       0.442808  0.033744  0.370061  0.418339     0.4486   0.469125   0.496475  0.001546\n",
      "t_subj.33       0.194124   0.01629  0.159525  0.184893    0.19402   0.204474   0.227464  0.000703\n",
      "t_subj.34       0.342166  0.031148  0.271032   0.32681   0.344034   0.359249    0.41325  0.001423\n",
      "t_subj.35       0.326166  0.023702  0.277839  0.311655   0.325471   0.339525   0.377445  0.001135\n",
      "t_subj.36       0.448541   0.01313  0.416465  0.442509   0.450736   0.457258    0.46902  0.000644\n",
      "t_subj.39       0.619483  0.011826  0.594743  0.612432   0.620983   0.627824   0.639493  0.000513\n",
      "t_subj.42       0.393689  0.016465  0.357252  0.383773   0.395154   0.405503   0.420903  0.000795\n",
      "t_subj.50       0.523493  0.019994   0.48242  0.504057   0.531437   0.539462   0.548079  0.001329\n",
      "t_subj.52       0.514666  0.022973  0.471141   0.49923   0.515226   0.529374   0.559297  0.000946\n",
      "t_subj.56       0.117791  0.010362  0.094589  0.111221   0.118186   0.124909   0.137946  0.000459\n",
      "t_subj.59        0.38001  0.022559  0.334866  0.362978    0.37847   0.401416   0.414784  0.001695\n",
      "t_subj.63       0.476758   0.02074  0.434167   0.46378   0.477949   0.491376   0.513955  0.000845\n",
      "t_subj.71        0.16272   0.00567  0.149944   0.15922   0.163047   0.166854   0.172524  0.000259\n",
      "t_subj.75       0.260613  0.006308  0.243858    0.2585     0.2622   0.264815   0.269012  0.000315\n",
      "t_subj.80       0.041755  0.017607  0.011514  0.028668   0.041091   0.054171   0.078246  0.000721\n",
      "alpha          -2.581239  0.377647 -3.338379 -2.836959  -2.568105  -2.312123  -1.844366  0.025669\n",
      "alpha_std       1.533793  0.282807  1.086185  1.331674   1.509172    1.69574   2.162631  0.017124\n",
      "alpha_subj.3   -3.581023  0.788421 -4.629034 -4.057254  -3.711833  -3.289853  -1.334163  0.063609\n",
      "alpha_subj.4    0.247822  0.645746 -0.769149 -0.199307   0.180743   0.589264   1.720519  0.030966\n",
      "alpha_subj.5   -3.521367  0.663483 -4.641201 -3.949771  -3.577666  -3.137793  -1.950833  0.047442\n",
      "alpha_subj.6    -3.88824   0.69867 -4.973127 -4.385679  -3.983322  -3.515576  -2.133692   0.06019\n",
      "alpha_subj.8   -2.644253  0.749256 -4.141863 -3.176522  -2.568348  -2.076175  -1.312179  0.061004\n",
      "alpha_subj.12  -1.007293  0.902407 -4.162341 -1.143816  -0.809802  -0.552392   0.005932  0.082096\n",
      "alpha_subj.17  -2.883803  0.427944 -3.741157 -3.155178  -2.877418  -2.616184  -2.033261  0.030961\n",
      "alpha_subj.18  -2.915168  0.443729 -3.721251 -3.231073  -2.932052  -2.591844   -2.03435  0.035426\n",
      "alpha_subj.19  -3.742551   0.23426 -4.213791 -3.892048  -3.727117  -3.586454  -3.284987  0.017391\n",
      "alpha_subj.20  -2.491476  0.414109 -3.289914  -2.77322  -2.500165  -2.214108  -1.677915  0.034025\n",
      "alpha_subj.22   -1.00055  0.206707 -1.419648 -1.132717  -1.008073  -0.857491  -0.598008  0.008023\n",
      "alpha_subj.23    -2.4047  1.122733 -4.393283 -3.444366  -2.144531  -1.538726  -0.528771   0.09735\n",
      "alpha_subj.24  -1.488625  0.214913  -1.93838 -1.624291  -1.478653  -1.336231  -1.108537  0.007126\n",
      "alpha_subj.26   0.572259  1.320584 -4.395052  0.155891   0.702695   1.186544   2.615145  0.099242\n",
      "alpha_subj.33  -3.406889  1.365327 -5.708369 -4.402333  -3.548211  -2.451892   -0.68433  0.093945\n",
      "alpha_subj.34  -3.223523  0.881207  -4.62955 -3.826056  -3.326855  -2.747707  -1.030801  0.061362\n",
      "alpha_subj.35  -2.769416  1.020386 -4.786738 -3.506265   -2.77138  -2.015596  -0.875673  0.083519\n",
      "alpha_subj.36   -2.44629  1.059799 -4.291163 -3.253262  -2.491277  -1.637371  -0.337187   0.08986\n",
      "alpha_subj.39  -3.627398  1.332921  -5.91941  -4.69478  -3.736182  -2.595158   -0.97683   0.09461\n",
      "alpha_subj.42  -3.098673  0.603089  -4.24481 -3.489485   -3.13063  -2.764182  -1.813547  0.052214\n",
      "alpha_subj.50  -3.974368  0.690171 -5.143549 -4.426537  -4.049831  -3.551653  -2.302475  0.056541\n",
      "alpha_subj.52  -3.526523  0.785399 -4.872212 -4.130031  -3.567962  -2.963909   -1.96076  0.070596\n",
      "alpha_subj.56  -4.027961  1.494496 -6.355385 -5.240879  -4.197692  -3.001012  -0.992752  0.121152\n",
      "alpha_subj.59  -2.548846  0.233853 -2.983605 -2.699344  -2.557573  -2.399138  -2.069415   0.01566\n",
      "alpha_subj.63  -2.068686  1.067186 -4.499142 -2.640239  -1.939177  -1.360812  -0.140205  0.083314\n",
      "alpha_subj.71  -3.022634  1.413943 -5.552288 -4.149162  -2.862369  -2.104246  -0.239175  0.112137\n",
      "alpha_subj.75  -1.443862  0.431426 -2.332285 -1.724323  -1.426375  -1.167307  -0.598566  0.020755\n",
      "alpha_subj.80   -3.25566  0.841692 -4.585491 -3.890789  -3.399611  -2.702483  -1.518016  0.067819\n",
      "DIC: 10121.088043\n",
      "deviance: 10059.042109\n",
      "pD: 62.045934\n"
     ]
    }
   ],
   "source": [
    "#run the model by calling hddm.HDDMrl (instead of hddm.HDDM for normal HDDM)\n",
    "m = hddm.HDDMrl(data)\n",
    "#set sample and burn-in\n",
    "m.sample(1500,burn=500,dbname='traces.db',db='pickle')\n",
    "#print stats to get an overview of posterior distribution of estimated parameters\n",
    "m.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/temp\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to run model in parallel\n",
    "def run_model(id):\n",
    "    print('running model %i'%id);\n",
    "    \n",
    "    import hddm\n",
    "    #import random\n",
    "\n",
    "    #exp_name = 'example'\n",
    "    #print('running models %i'%id, 'for for exp', exp_name)\n",
    "    \n",
    "    # USE the absolute directory in docker.\n",
    "    dbname = '/home/jovyan/hddm/tutorial/rlhddm_chain_%i.db'%id # define the database name, which uses pickle format\n",
    "    mname  = '/home/jovyan/hddm/tutorial/rlhddm_chain_%i'%id    # define the name for the model\n",
    "    fname  = '/home/jovyan/hddm/tutorial/rlddm_data.csv'\n",
    "    df = hddm.load_csv(fname)\n",
    "    \n",
    "    m = hddm.HDDMrl(df)\n",
    "    # m.find_starting_values()\n",
    "    m.sample(1500,burn=500, dbname=dbname, db='pickle')\n",
    "    m.save(mname)\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 0\n",
    "dbname = '/home/jovyan/hddm/tutorial/rlhddm_chain_%i.db'%id # define the database name, which uses pickle format\n",
    "mname  = '/home/jovyan/hddm/tutorial/rlhddm_chain_%i'%id    # define the name for the model\n",
    "fname  = '/home/jovyan/hddm/tutorial/rlddm_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = hddm.load_csv(fname)\n",
    "    \n",
    "m = hddm.HDDMrl(df)\n",
    "# m.find_starting_values()\n",
    "m.sample(1500,burn=500, dbname=dbname, db='pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save(mname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()  # the start time of the processing\n",
    "\n",
    "m = run_model(0)\n",
    "\n",
    "print(\"\\nRunning 1 chain used: %f seconds.\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def wait_watching_stdout(ar, dt=10):\n",
    "    \"\"\"\n",
    "    ar: vmap output of the models being run \n",
    "    dt: number of seconds between checking output, you can make is shorter or longer.\n",
    "    \"\"\"\n",
    "\n",
    "    while not ar.ready():\n",
    "        stdouts = ar.stdout\n",
    "        if not any(stdouts):\n",
    "            continue\n",
    "        # clear_output doesn't do much in terminal environments\n",
    "        clear_output()\n",
    "        print('-' * 30)\n",
    "        print(\"%.3fs elapsed\" % ar.elapsed)\n",
    "        print(\"\")\n",
    "        for out in ar.stdout: print(out);\n",
    "        sys.stdout.flush()\n",
    "        time.sleep(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyparallel import Client\n",
    "start_time = time.time()  # the start time of the processing\n",
    "v = Client()[:]\n",
    "jobs = v.map(run_model, range(4)) # 4 is the number of CPUs\n",
    "wait_watching_stdout(jobs)\n",
    "models = jobs.get()\n",
    "\n",
    "m1_time = time.time() \n",
    "print(\"\\nRunning 4 chains used: %f seconds.\" % (m1_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Interpreting output from print_stats:__  <br>\n",
    "The model estimates group mean and standard deviation parameters and subject parameters for the following latent variables: <br>\n",
    "a = decision threshold <br>\n",
    "v = scaling parameter <br>\n",
    "t = non-decision time <br>\n",
    "alpha = learning rate, note that it's not bound between 0 and 1. to transform take inverse logit: np.exp(alpha)/(1+np.exp(alpha)) <br>\n",
    "The columns represent the mean, standard deviation and quantiles of the approximated posterior distribution of each parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDDMrl vs. HDDM\n",
    "__There are a few things to note that is different from the normal HDDM model.__ <br>\n",
    "First of all, the estimated learning rate does not necessarily fall between 0 and 1. This is because it is estimated as a normal distribution for purposes of sampling hierarchically and then transformed by an inverse logit function to 0<alpha<1. So to interpret alpha as learning rate you have to transform the samples in the trace back with np.exp(alpha)/(1+np.exp(alpha)). And if you estimate separate learning rates for positive and negative prediction errors ([see here](#9.-Separate-learning-rates-for-positive-and-negative-prediction-errors)) then you get learning rate for negative prediction errors with np.exp(alpha)/(1+np.exp(alpha)) and positive prediction errors with np.exp(pos_alpha)/(1+np.exp(pos_alpha)).<br>\n",
    "Second, the v-parameter in the output is the scaling factor that is multiplied by the difference in q-values, so it is not the actual drift rate (or rather, it is the equivalent drift rate when the difference in Q values is exactly 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Checking results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the posteriors of parameters \n",
    "m.plot_posteriors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fig__. The mixing of the posterior distribution and autocorrelation looks ok."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convergence of chains\n",
    "The Gelman-Rubin statistic is a test of whether the chains in the model converges. The Gelman-Ruben statistic measures the degree of variation between and within chains. Values close to 1 indicate convergence and that there is small variation between chains, i.e. that they end up as the same distribution across chains. A common heuristic is to assume convergence if all values are below 1.1. To run this you need to run multiple models, combine them and perform the Gelman-Rubin statistic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate convergence\n",
    "from kabuki.analyze import gelman_rubin\n",
    "\n",
    "models = []\n",
    "for i in range(3):\n",
    "    m = hddm.HDDMrl(data=data)\n",
    "    m.sample(1500, burn=500,dbname='traces.db',db='pickle')\n",
    "    models.append(m)\n",
    "\n",
    "gelman_rubin(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(list(gelman_rubin(models).values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model seems to have converged, i.e. the Gelman-Rubin statistic is below 1.1 for all parameters. It is important to always run this test, especially for more complex models ([as with separate learning rates for positive and negative prediction errors](#9.-Separate-learning-rates-for-positive-and-negative-prediction-errors)). So now we can combine these three models to get a better approximation of the posterior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the models we ran to test for convergence.\n",
    "m = kabuki.utils.concat_models(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint posterior distribution\n",
    "Another test of the model is to look at collinearity. If the estimation of parameters is very codependent (correlation is strong) it can indicate that their variance trades off, in particular if there is a negative correlation. The following plot shows there is generally low correlation across all combinations of parameters. It does not seem to be the case for this dataset, but common for RLDDM is a negative correlation between learning rate and the scaling factor, similar to what's usually observed between learning rate and inverse temperature for RL models that uses softmax as the choice rule (e.g. [Daw, 2011](https://www.oxfordscholarship.com/view/10.1093/acprof:oso/9780199600434.001.0001/acprof-9780199600434-chapter-001))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha, t, a, v = m.nodes_db.node[['alpha', 't', 'a','v']]\n",
    "samples = {'alpha':alpha.trace(),'t':t.trace(),'a':a.trace(),'v':v.trace()}\n",
    "samp = pd.DataFrame(data=samples)\n",
    "\n",
    "def corrfunc(x, y, **kws):\n",
    "    r, _ = stats.pearsonr(x, y)\n",
    "    ax = plt.gca()\n",
    "    ax.annotate(\"r = {:.2f}\".format(r),\n",
    "                xy=(.1, .9), xycoords=ax.transAxes)\n",
    "\n",
    "g = sns.PairGrid(samp, palette=[\"red\"])\n",
    "g.map_upper(plt.scatter, s=10)\n",
    "g.map_diag(sns.distplot, kde=False)\n",
    "g.map_lower(sns.kdeplot, cmap=\"Blues_d\")\n",
    "g.map_lower(corrfunc)\n",
    "g.savefig('matrix_plot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Posterior predictive checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important test of the model is its ability to recreate the observed data. This can be tested with posterior predictive checks, which involves simulating data using estimated parameters and comparing observed and simulated results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract traces\n",
    "The first step then is to extract the traces from the estimated model. The function get_traces() gives you the samples (row) from the approaximated posterior distribution for all of the estimated group and subject parameters (column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = m.get_traces()\n",
    "traces.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simulating data\n",
    "__Now that we have the traces the next step is to simulate data using the estimated parameters. The RLDDM includes a function to simulate data. Here's an example of how to use the simulation-function for RLDDM. This example explains how to generate data with binary outcomes. See [here](#11.-Probabilistic-binary-outcomes-vs.-normally-distributed-outcomes) for an example on simulating data with normally distributed outcomes. Inputs to function: <br>\n",
    "a__ = decision threshold <br>\n",
    "**t** = non-decision time <br>\n",
    "__alpha__ = learning rate <br>\n",
    "__pos_alpha__ = defaults to 0. if given it defines the learning rate for positive prediction errors. alpha then becomes the learning rate_ for negative prediction errors.  <br>\n",
    "__scaler__ = the scaling factor that is multiplied with the difference in q-values to calculate trial-by-trial drift rate <br>\n",
    "__p_upper__ = the probability of reward for the option represented by the upper boundary. The current version thus only works for outcomes that are either 1 or 0 <br>\n",
    "__p_lower__ = the probability of reward for the option represented by the lower boundary. <br>\n",
    "__subjs__ = number of subjects to simulate data for. <br>\n",
    "__split_by__ = define the condition which makes it easier to append data from different conditions. <br>\n",
    "__size__ = number of trials per subject. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hddm.generate.gen_rand_rlddm_data(a=1,t=0.3,alpha=0.2,scaler=2,p_upper=0.8,p_lower=0.2,subjs=1,split_by=0,size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__How to interpret columns in the resulting dataframe__ <br>\n",
    "__q_up__ = expected reward for option represented by upper boundary <br>\n",
    "__q_low__ = expected reward for option represented by lower boundary <br>\n",
    "__sim_drift__ = the drift rate for each trial calculated as: (q_up-q_low)*scaler <br>\n",
    "__response__ = simulated choice <br>\n",
    "__rt__ = simulated response time <br>\n",
    "__feedback__ = observed feedback for chosen option <br>\n",
    "__subj_idx__ = subject id (starts at 0) <br>\n",
    "__split_by__ = condition as integer <br>\n",
    "__trial__ = current trial (starts at 1) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate data with estimated parameter values and compare to observed data\n",
    "Now that we know how to extract traces and simulate data we can combine this to create a dataset similar to our observed data. This process is currently not automated but the following is an example code using the dataset we analyzed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm #progress tracker\n",
    "#create empty dataframe to store simulated data\n",
    "sim_data = pd.DataFrame()\n",
    "#create a column samp to be used to identify the simulated data sets\n",
    "data['samp'] = 0\n",
    "#load traces\n",
    "traces = m.get_traces()\n",
    "#decide how many times to repeat simulation process. repeating this multiple times is generally recommended, \n",
    "#as it better captures the uncertainty in the posterior distribution, but will also take some time\n",
    "for i in tqdm(range(1,51)):\n",
    "    #randomly select a row in the traces to use for extracting parameter values\n",
    "    sample = np.random.randint(0,traces.shape[0]-1)\n",
    "    #loop through all subjects in observed data\n",
    "    for s in data.subj_idx.unique():\n",
    "        #get number of trials for each condition.\n",
    "        size0 = len(data[(data['subj_idx']==s) & (data['split_by']==0)].trial.unique())\n",
    "        size1 = len(data[(data['subj_idx']==s) & (data['split_by']==1)].trial.unique())\n",
    "        size2 = len(data[(data['subj_idx']==s) & (data['split_by']==2)].trial.unique())\n",
    "        #set parameter values for simulation\n",
    "        a = traces.loc[sample,'a_subj.'+str(s)]\n",
    "        t = traces.loc[sample,'t_subj.'+str(s)]\n",
    "        scaler = traces.loc[sample,'v_subj.'+str(s)]\n",
    "        alphaInv = traces.loc[sample,'alpha_subj.'+str(s)]\n",
    "        #take inverse logit of estimated alpha\n",
    "        alpha = np.exp(alphaInv)/(1+np.exp(alphaInv))\n",
    "        #simulate data for each condition changing only values of size, p_upper, p_lower and split_by between conditions.\n",
    "        sim_data0 = hddm.generate.gen_rand_rlddm_data(a=a,t=t,scaler=scaler,alpha=alpha,size=size0,p_upper=0.8,p_lower=0.2,split_by=0)\n",
    "        sim_data1 = hddm.generate.gen_rand_rlddm_data(a=a,t=t,scaler=scaler,alpha=alpha,size=size1,p_upper=0.7,p_lower=0.3,split_by=1)\n",
    "        sim_data2 = hddm.generate.gen_rand_rlddm_data(a=a,t=t,scaler=scaler,alpha=alpha,size=size2,p_upper=0.6,p_lower=0.4,split_by=2)\n",
    "        #append the conditions\n",
    "        sim_data0 = sim_data0.append([sim_data1,sim_data2],ignore_index=True)\n",
    "        #assign subj_idx\n",
    "        sim_data0['subj_idx'] = s\n",
    "        #identify that these are simulated data\n",
    "        sim_data0['type'] = 'simulated'\n",
    "        #identify the simulated data\n",
    "        sim_data0['samp'] = i\n",
    "        #append data from each subject\n",
    "        sim_data = sim_data.append(sim_data0,ignore_index=True)\n",
    "#combine observed and simulated data\n",
    "ppc_data = data[['subj_idx','response','split_by','rt','trial','feedback','samp']].copy()\n",
    "ppc_data['type'] = 'observed'\n",
    "ppc_sdata = sim_data[['subj_idx','response','split_by','rt','trial','feedback','type','samp']].copy()\n",
    "ppc_data = ppc_data.append(ppc_sdata)\n",
    "ppc_data.to_csv('ppc_data_tutorial.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting\n",
    "Now that we have a dataframe with both observed and simulated data we can plot to see whether the simulated data are able to capture observed choice and reaction times. To capture the uncertainty in the simulated data we want to identify how much choice and reaction differs across the simulated data sets. A good measure of this is to calculate the highest posterior density/highest density interval for summary scores of the generated data. Below we calculate highest posterior density with an alpha set to 0.1, which means that we are describing the range of the 90% most likely values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for practical reasons we only look at the first 40 trials for each subject in a given condition\n",
    "plot_ppc_data = ppc_data[ppc_data.trial<41].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bin trials to for smoother estimate of response proportion across learning\n",
    "plot_ppc_data['bin_trial'] = pd.cut(plot_ppc_data.trial,11,labels=np.linspace(0, 10,11)).astype('int64')\n",
    "#calculate means for each sample\n",
    "sums = plot_ppc_data.groupby(['bin_trial','split_by','samp','type']).mean().reset_index()\n",
    "#calculate the overall mean response across samples\n",
    "ppc_sim = sums.groupby(['bin_trial','split_by','type']).mean().reset_index()\n",
    "#initiate columns that will have the upper and lower bound of the hpd\n",
    "ppc_sim['upper_hpd'] = 0\n",
    "ppc_sim['lower_hpd'] = 0\n",
    "for i in range(0,ppc_sim.shape[0]):\n",
    "    #calculate the hpd/hdi of the predicted mean responses across bin_trials\n",
    "    hdi = pymc.utils.hpd(sums.response[(sums['bin_trial']==ppc_sim.bin_trial[i]) & (sums['split_by']==ppc_sim.split_by[i]) & (sums['type']==ppc_sim.type[i])],alpha=0.1)\n",
    "    ppc_sim.loc[i,'upper_hpd'] = hdi[1]\n",
    "    ppc_sim.loc[i,'lower_hpd'] = hdi[0]\n",
    "#calculate error term as the distance from upper bound to mean\n",
    "ppc_sim['up_err'] = ppc_sim['upper_hpd']-ppc_sim['response']\n",
    "ppc_sim['low_err'] = ppc_sim['response']-ppc_sim['lower_hpd']\n",
    "ppc_sim['model'] = 'RLDDM_single_learning'\n",
    "ppc_sim.to_csv('ppc_choicedata_tutorial.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting evolution of choice proportion for best option across learning for observed and simulated data.\n",
    "fig, axs = plt.subplots(figsize=(15, 5),nrows=1, ncols=3, sharex=True,sharey=True)\n",
    "for i in range(0,3):\n",
    "    ax = axs[i]\n",
    "    d = ppc_sim[(ppc_sim.split_by==i) & (ppc_sim.type=='simulated')]\n",
    "    ax.errorbar(d.bin_trial, d.response, yerr=[d.low_err,d.up_err], label='simulated',color='orange')\n",
    "    d = ppc_sim[(ppc_sim.split_by==i) & (ppc_sim.type=='observed')]\n",
    "    ax.plot(d.bin_trial, d.response,linewidth=3,label='observed')\n",
    "    ax.set_title('split_by = %i' %i,fontsize=20)\n",
    "    ax.set_ylabel('mean response')\n",
    "    ax.set_xlabel('trial')\n",
    "plt.legend()\n",
    "fig.savefig('PPCchoice.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fig.__ The plots display the rate of choosing the best option (response = 1) across learning and condition. The model generates data (orange) that closely follows the observed behavior (blue), with the exception of overpredicting performance early in the most difficult condition (split_by=2). Uncertainty in the generated data is captured by the 90% highest density interval of the means across simulated datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set reaction time to be negative for lower bound responses (response=0)\n",
    "plot_ppc_data['reaction time'] = np.where(plot_ppc_data['response']==1,plot_ppc_data.rt,0-plot_ppc_data.rt)\n",
    "#plotting evolution of choice proportion for best option across learning for observed and simulated data. We use bins of trials because plotting individual trials would be very noisy. \n",
    "g = sns.FacetGrid(plot_ppc_data,col='split_by',hue='type')\n",
    "g.map(sns.kdeplot, 'reaction time',bw=0.05).set_ylabels(\"Density\")\n",
    "g.add_legend()\n",
    "g.savefig('PPCrt_dist.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fig.__ Density plots of observed and predicted reaction time across conditions. RTs for lower boundary choices (i.e. worst option choices) are set to be negative (0-RT) to be able to separate upper and lower bound responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Parameter recovery\n",
    "To validate the RLDDM we ran a parameter recovery study to test to which degree the model can recover the parameter values used to simulate data. To do this we generated 81 synthetic datasets with 50 subjects performing 70 trials each. The 81 datasets were simulated using all combinations of three plausible parameter values for decision threshold, non-decision time, learning rate and the scaling parameter onto drift rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimated values split by simulated vales \n",
    "We can plot simulated together with the estimated values to test the models ability to recover parameters, and to see if there are any values that are more difficult to recover than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_recovery = hddm.load_csv('recovery_sim_est_rlddm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x='a',y='e_a',data=param_recovery,palette='Set1')\n",
    "g.set_axis_labels(\"Simulated threshold\", \"Estimated threshold\")\n",
    "plt.title(\"Decision threshold\")\n",
    "g.savefig('Threshold_recovery.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x='alpha',y='e_alphaT',data=param_recovery,palette='Set1')\n",
    "g.set_axis_labels(\"Simulated alpha\", \"Estimated alpha\")\n",
    "plt.title(\"Learning rate\")\n",
    "g.savefig('Alpha_recovery.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x='scaler',y='e_v',data=param_recovery,palette='Set1')\n",
    "g.set_axis_labels(\"Simulated scaling\", \"Estimated scaling\")\n",
    "plt.title(\"Scaling drift rate\")\n",
    "g.savefig('Scaler_recovery.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x='t',y='e_t',data=param_recovery,palette='Set1')\n",
    "g.set_axis_labels(\"Simulated NDT\", \"Estimated NDT\")\n",
    "plt.title(\"Non-decision time\")\n",
    "g.savefig('NDT_recovery.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fig.__ The correlation between simulated and estimated parameter values are high, which means recovery is good. There is somewhat worse recovery for the learning rate and scaling parameter, which makes sense given that they to a degree can explain the same variance (see below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Separate learning rates for positive and negative prediction errors\n",
    "Several studies have reported differences in updating of expected rewards following positive and negative prediction errors (e.g. to capture differences between D1 and D2 receptor function). To model asymmetric updating rates for positive and negative prediction errors you can set dual=True in the model. This will produce two estimated learning rates; alpha and pos_alpha, of which alpha then becomes the estimated learning rate for negative prediction errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set dual=True to model separate learning rates for positive and negative prediction errors.\n",
    "m_dual = hddm.HDDMrl(data,dual=True)\n",
    "#set sample and burn-in\n",
    "m_dual.sample(1500,burn=500,dbname='traces.db',db='pickle')\n",
    "#print stats to get an overview of posterior distribution of estimated parameters\n",
    "m_dual.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_dual.plot_posteriors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fig.__ There's more autocorrelation in this model compared to the one with a single learning rate. First, let's test whether it converges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate convergence\n",
    "models = []\n",
    "for i in range(3):\n",
    "    m = hddm.HDDMrl(data=data,dual=True)\n",
    "    m.sample(1500, burn=500,dbname='traces.db',db='pickle')\n",
    "    models.append(m)\n",
    "\n",
    "#get max gelman-statistic value. shouldn't be higher than 1.1\n",
    "np.max(list(gelman_rubin(models).values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gelman_rubin(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convergence looks good, i.e. no parameters with gelman-rubin statistic > 1.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model that has all traces concatenated\n",
    "# of individual models.\n",
    "m_dual = kabuki.utils.concat_models(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we can have a look at the joint posterior distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha, t, a, v, pos_alpha = m_dual.nodes_db.node[['alpha', 't', 'a','v','pos_alpha']]\n",
    "samples = {'alpha':alpha.trace(),'pos_alpha':pos_alpha.trace(),'t':t.trace(),'a':a.trace(),'v':v.trace()}\n",
    "samp = pd.DataFrame(data=samples)\n",
    "\n",
    "def corrfunc(x, y, **kws):\n",
    "    r, _ = stats.pearsonr(x, y)\n",
    "    ax = plt.gca()\n",
    "    ax.annotate(\"r = {:.2f}\".format(r),\n",
    "                xy=(.1, .9), xycoords=ax.transAxes)\n",
    "\n",
    "g = sns.PairGrid(samp, palette=[\"red\"])\n",
    "g.map_upper(plt.scatter, s=10)\n",
    "g.map_diag(sns.distplot, kde=False)\n",
    "g.map_lower(sns.kdeplot, cmap=\"Blues_d\")\n",
    "g.map_lower(corrfunc)\n",
    "g.savefig('matrix_plot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fig.__ The correlation between parameters is generally low. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior predictive check\n",
    "The DIC for this dual learning rate model is better than for the single learning rate model. We can therefore check whether we can detect this improvement in the ability to recreate choice and RT patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty dataframe to store simulated data\n",
    "sim_data = pd.DataFrame()\n",
    "#create a column samp to be used to identify the simulated data sets\n",
    "data['samp'] = 0\n",
    "#get traces, note here we extract traces from m_dual\n",
    "traces = m_dual.get_traces()\n",
    "#decide how many times to repeat simulation process. repeating this multiple times is generally recommended as it better captures the uncertainty in the posterior distribution, but will also take some time\n",
    "for i in tqdm(range(1,51)):\n",
    "    #randomly select a row in the traces to use for extracting parameter values\n",
    "    sample = np.random.randint(0,traces.shape[0]-1)\n",
    "    #loop through all subjects in observed data\n",
    "    for s in data.subj_idx.unique():\n",
    "        #get number of trials for each condition.\n",
    "        size0 = len(data[(data['subj_idx']==s) & (data['split_by']==0)].trial.unique())\n",
    "        size1 = len(data[(data['subj_idx']==s) & (data['split_by']==1)].trial.unique())\n",
    "        size2 = len(data[(data['subj_idx']==s) & (data['split_by']==2)].trial.unique())\n",
    "        #set parameter values for simulation\n",
    "        a = traces.loc[sample,'a_subj.'+str(s)]\n",
    "        t = traces.loc[sample,'t_subj.'+str(s)]\n",
    "        scaler = traces.loc[sample,'v_subj.'+str(s)]\n",
    "        #when generating data with two learning rates pos_alpha represents learning rate for positive prediction errors and alpha for negative prediction errors\n",
    "        alphaInv = traces.loc[sample,'alpha_subj.'+str(s)]\n",
    "        pos_alphaInv = traces.loc[sample,'pos_alpha_subj.'+str(s)]\n",
    "        #take inverse logit of estimated alpha and pos_alpha\n",
    "        alpha = np.exp(alphaInv)/(1+np.exp(alphaInv))\n",
    "        pos_alpha = np.exp(pos_alphaInv)/(1+np.exp(pos_alphaInv))\n",
    "        #simulate data for each condition changing only values of size, p_upper, p_lower and split_by between conditions.\n",
    "        sim_data0 = hddm.generate.gen_rand_rlddm_data(a=a,t=t,scaler=scaler,alpha=alpha,pos_alpha=pos_alpha,size=size0,p_upper=0.8,p_lower=0.2,split_by=0)\n",
    "        sim_data1 = hddm.generate.gen_rand_rlddm_data(a=a,t=t,scaler=scaler,alpha=alpha,pos_alpha=pos_alpha,size=size1,p_upper=0.7,p_lower=0.3,split_by=1)\n",
    "        sim_data2 = hddm.generate.gen_rand_rlddm_data(a=a,t=t,scaler=scaler,alpha=alpha,pos_alpha=pos_alpha,size=size2,p_upper=0.6,p_lower=0.4,split_by=2)\n",
    "        #append the conditions\n",
    "        sim_data0 = sim_data0.append([sim_data1,sim_data2],ignore_index=True)\n",
    "        #assign subj_idx\n",
    "        sim_data0['subj_idx'] = s\n",
    "        #identify that these are simulated data\n",
    "        sim_data0['type'] = 'simulated'\n",
    "        #identify the simulated data\n",
    "        sim_data0['samp'] = i\n",
    "        #append data from each subject\n",
    "        sim_data = sim_data.append(sim_data0,ignore_index=True)\n",
    "#combine observed and simulated data\n",
    "ppc_dual_data = data[['subj_idx','response','split_by','rt','trial','feedback','samp']].copy()\n",
    "ppc_dual_data['type'] = 'observed'\n",
    "ppc_dual_sdata = sim_data[['subj_idx','response','split_by','rt','trial','feedback','type','samp']].copy()\n",
    "ppc_dual_data = ppc_dual_data.append(ppc_dual_sdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for practical reasons we only look at the first 40 trials for each subject in a given condition\n",
    "plot_ppc_dual_data = ppc_dual_data[ppc_dual_data.trial<41].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bin trials to for smoother estimate of response proportion across learning\n",
    "plot_ppc_dual_data['bin_trial'] = pd.cut(plot_ppc_dual_data.trial,11,labels=np.linspace(0, 10,11)).astype('int64')\n",
    "#calculate means for each sample\n",
    "sums = plot_ppc_dual_data.groupby(['bin_trial','split_by','samp','type']).mean().reset_index()\n",
    "#calculate the overall mean response across samples\n",
    "ppc_dual_sim = sums.groupby(['bin_trial','split_by','type']).mean().reset_index()\n",
    "#initiate columns that will have the upper and lower bound of the hpd\n",
    "ppc_dual_sim['upper_hpd'] = 0\n",
    "ppc_dual_sim['lower_hpd'] = 0\n",
    "for i in range(0,ppc_dual_sim.shape[0]):\n",
    "    #calculate the hpd/hdi of the predicted mean responses across bin_trials\n",
    "    hdi = pymc.utils.hpd(sums.response[(sums['bin_trial']==ppc_dual_sim.bin_trial[i]) & (sums['split_by']==ppc_dual_sim.split_by[i]) & (sums['type']==ppc_dual_sim.type[i])],alpha=0.1)\n",
    "    ppc_dual_sim.loc[i,'upper_hpd'] = hdi[1]\n",
    "    ppc_dual_sim.loc[i,'lower_hpd'] = hdi[0]\n",
    "#calculate error term as the distance from upper bound to mean\n",
    "ppc_dual_sim['up_err'] = ppc_dual_sim['upper_hpd']-ppc_dual_sim['response']\n",
    "ppc_dual_sim['low_err'] = ppc_dual_sim['response']-ppc_dual_sim['lower_hpd']\n",
    "ppc_dual_sim['model'] = 'RLDDM_dual_learning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting evolution of choice proportion for best option across learning for observed and simulated data.\n",
    "fig, axs = plt.subplots(figsize=(15, 5),nrows=1, ncols=3, sharex=True,sharey=True)\n",
    "for i in range(0,3):\n",
    "    ax = axs[i]\n",
    "    d = ppc_dual_sim[(ppc_dual_sim.split_by==i) & (ppc_dual_sim.type=='simulated')]\n",
    "    ax.errorbar(d.bin_trial, d.response, yerr=[d.low_err,d.up_err], label='simulated',color='orange')\n",
    "    d = ppc_sim[(ppc_dual_sim.split_by==i) & (ppc_dual_sim.type=='observed')]\n",
    "    ax.plot(d.bin_trial, d.response,linewidth=3,label='observed')\n",
    "    ax.set_title('split_by = %i' %i,fontsize=20)\n",
    "    ax.set_ylabel('mean response')\n",
    "    ax.set_xlabel('trial')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fig.__ The plots display the rate of choosing the best option (response = 1) across learning and condition. The model generates data (orange) that closely follows the observed behavior (blue), with the exception of performance early in the most difficult condition (split_by=2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPC for single vs. dual learning rate\n",
    "To get a better sense of differences in ability to predict data between the single and dual learning rate model we can plot them together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting evolution of choice proportion for best option across learning for observed and simulated data. Compared for model with single and dual learning rate.\n",
    "fig, axs = plt.subplots(figsize=(15, 5),nrows=1, ncols=3, sharex=True,sharey=True)\n",
    "for i in range(0,3):\n",
    "    ax = axs[i]\n",
    "    d_single = ppc_sim[(ppc_sim.split_by==i) & (ppc_sim.type=='simulated')]\n",
    "    #slightly move bin_trial to avoid overlap in errorbars\n",
    "    d_single['bin_trial'] += 0.2\n",
    "    ax.errorbar(d_single.bin_trial, d_single.response, yerr=[d_single.low_err,d_single.up_err],label='simulated_single',color='orange')\n",
    "    d_dual = ppc_dual_sim[(ppc_dual_sim.split_by==i) & (ppc_dual_sim.type=='simulated')]\n",
    "    ax.errorbar(d_dual.bin_trial, d_dual.response, yerr=[d_dual.low_err,d_dual.up_err],label='simulated_dual',color='green')\n",
    "    d = ppc_sim[(ppc_dual_sim.split_by==i) & (ppc_dual_sim.type=='observed')]\n",
    "    ax.plot(d.bin_trial, d.response,linewidth=3,label='observed')\n",
    "    ax.set_title('split_by = %i' %i,fontsize=20)\n",
    "    ax.set_ylabel('mean response')\n",
    "    ax.set_xlabel('trial')\n",
    "plt.xlim(-0.5,10.5)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fig.__ The predictions from the model with two learning rates are not very different from the model with single learning rate, and a similar overprediction of performance early on for the most difficult condition (split_by =2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ppc_data['type_compare'] = np.where(plot_ppc_data['type']=='observed',plot_ppc_data['type'],'simulated_single_learning')\n",
    "plot_ppc_dual_data['type_compare'] = np.where(plot_ppc_dual_data['type']=='observed',plot_ppc_dual_data['type'],'simulated_dual_learning')\n",
    "dual_vs_single_pcc = plot_ppc_data.append(plot_ppc_dual_data)\n",
    "dual_vs_single_pcc['reaction time'] = np.where(dual_vs_single_pcc['response']==1,dual_vs_single_pcc.rt,0-dual_vs_single_pcc.rt)\n",
    "#plotting evolution of choice proportion for best option across learning for observed and simulated data. We use bins of trials because plotting individual trials would be very noisy. \n",
    "g = sns.FacetGrid(dual_vs_single_pcc,col='split_by',hue='type_compare',height=5)\n",
    "g.map(sns.kdeplot, 'reaction time',bw=0.01).set_ylabels(\"Density\")\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fig.__ Again there's not a big difference between the two models. Both models slightly overpredict performance for the medium (split_by =1) and hard (split_by = 2) conditions, as identified by lower densities for the negative (worst option choices) in the simulated compared to observed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform alpha and pos_alpha\n",
    "To interpret the parameter estimates for alpha and pos_alpha you have to transform them with the inverse logit where learning rate for negative prediction error is alpha and learning rate for positive prediction errors is pos_alpha. For this dataset the learning rate is estimated to be higher for positive than negative prediction errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot alpha for positive and negative learning rate\n",
    "traces = m_dual.get_traces()\n",
    "neg_alpha = np.exp(traces['alpha'])/(1+np.exp(traces['alpha']))\n",
    "pos_alpha = np.exp(traces['pos_alpha'])/(1+np.exp(traces['pos_alpha']))\n",
    "sns.kdeplot(neg_alpha, color='r', label=\"neg_alpha: \" + str(np.round(np.mean(neg_alpha),3)))\n",
    "sns.kdeplot(pos_alpha, color='b', label=\"pos_alpha: \" + str(np.round(np.mean(pos_alpha),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fig.__ The positive learning rate is estimated to be stronger than the negative learning rate. Sticky choice, tendencies to repeat choices, could be driving some of this difference. The current model does not allow to test for this, however, but it could be tested in the future if we implement a regression version of RLDDM (similar to HDDMRegressor)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate data with learning rates for positive and negative prediction errors\n",
    "Here's how you would simulate data with a learning rate for positive and negative predictions of 0.2 and 0.4, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hddm.generate.gen_rand_rlddm_data(a=1,t=0.3,alpha=0.2,pos_alpha=0.4,scaler=2,p_upper=0.8,p_lower=0.2,size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. depends_on vs. split_by\n",
    "HDDMrl can be used to estimate separate parameters just as in the standard HDDM. But in RL you typically estimate the same learning rates and inverse temperature across conditions. That's one reason why you have to specify condition in the split_by-column instead of depends_on. (The other is that if you use depends_on the expected rewards will not get updated properly). But depends_on is still useful, for example if you want to estimate the effect of group on parameters. As an example we can simulate a dataset with two groups that have different decision thresholds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = hddm.generate.gen_rand_rlddm_data(a=1,t=0.3,alpha=0.4,scaler=2,p_upper=0.8,p_lower=0.2,subjs=50,size=50)\n",
    "data1['group'] = 'group1'\n",
    "data2 = hddm.generate.gen_rand_rlddm_data(a=2,t=0.3,alpha=0.4,scaler=2,p_upper=0.8,p_lower=0.2,subjs=50,size=50)\n",
    "data2['group'] = 'group2'\n",
    "group_data = data1.append(data2)\n",
    "group_data['q_init'] = 0.5\n",
    "m = hddm.HDDMrl(group_data,depends_on={'v':'group','a':'group','t':'group','alpha':'group'})\n",
    "m.sample(1500,burn=500,dbname='traces.db',db='pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the plot shows that the model was able to recover the different decision threshold across groups.\n",
    "a_group1, a_group2 = m.nodes_db.node[['a(group1)', 'a(group2)']]\n",
    "hddm.analyze.plot_posterior_nodes([a_group1, a_group2])\n",
    "plt.xlabel('decision threshold')\n",
    "plt.ylabel('Posterior probability')\n",
    "plt.xlim(0.7,2.3)\n",
    "plt.title('Posterior of decision threshold group means')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Probabilistic binary outcomes vs. normally distributed outcomes\n",
    "The examples so far have all been using a task structure where the outcomes are binary and probabilistic. But the model can also be applied to other types of outcomes. Here we show how you can generate and model data with normally distributed outcomes. As you will see you don't have to do any modifications to the model estimation process, but you have to change the input for generating data. Also note that the scaling parameter (v) will scale negatively with the values of the observed outcomes because the combined drift rate needs to be plausible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how we generated data so far, defining the probability of reward (1) for actions/stimuli associated with upper and lower boundary.\n",
    "# binary probabilistic outcomes\n",
    "hddm.generate.gen_rand_rlddm_data(a=2,t=0.3,scaler=2,alpha=0.2,size=10,p_upper=0.2,p_lower=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If instead the outcomes are drawn from a normal distribution you will have to set binary_outcome to False and instead of p_upper and p_upper define the mean (mu) and sd \n",
    "# of the normal distribution for both alternatives. Note that we change the initial q-value to 0, and that we reduce the scaling factor.\n",
    "# normally distributed outcomes\n",
    "hddm.generate.gen_rand_rlddm_data(a=2,t=0.3,scaler=0.2,alpha=0.2,size=10,mu_upper=8,mu_lower=2,sd_upper=1,sd_lower=1,binary_outcome=False,q_init=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can generate a dataset where 30 subjects perform 50 trials each. Note that we set the scaler to be lower than for the binary outcomes as otherwise \n",
    "# the resulting drift will be unrealistically high.\n",
    "norm_data = hddm.generate.gen_rand_rlddm_data(a=2,t=0.3,scaler=0.2,alpha=0.2,size=50,subjs=30,mu_upper=8,mu_lower=2,sd_upper=2,sd_lower=2,binary_outcome=False,q_init=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#and then we can do estimation as usual\n",
    "#but first we need to define inital q-value\n",
    "norm_data['q_init'] = 0\n",
    "m_norm = hddm.HDDMrl(norm_data)\n",
    "m_norm.sample(1500,burn=500,dbname='traces.db',db='pickle')\n",
    "m_norm.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. HDDMrlRegressor\n",
    "\n",
    "As of version 0.7.6. HDDM includes a module for estimating the impact of continuous regressor onto RLDDM parameters. The module, called HDDMrlRegressor, works the same way as the HDDMRegressor for the normal DDM. The method allows estimation of the association of e.g. neural measures onto parameters. To illustrate the method we extend the function to generate rlddm_data by adding a normally distributed regressor and including a coefficient called 'neural'.Note that to run the HDDMrlRegressor you need to include alpha when specifying the model. For more information on how to set up regressor models look at the tutorial for HDDM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to generate rlddm-data that adds a neural regressor to decision threshold\n",
    "def gen_rand_reg_rlddm_data(a, t, scaler, alpha, neural, size=1, p_upper=1, p_lower=0, z=0.5, q_init=0.5, split_by=0, subjs=1):\n",
    "    all_data = []\n",
    "    n = size\n",
    "    # set sd for variables to generate subject-parameters from group distribution\n",
    "    sd_t = 0.02\n",
    "    sd_a = 0.1\n",
    "    sd_alpha = 0.1\n",
    "    sd_v = 0.25\n",
    "    #save parameter values as group-values\n",
    "    tg = t\n",
    "    ag = a\n",
    "    alphag = alpha\n",
    "    scalerg = scaler\n",
    "    for s in range(0, subjs):\n",
    "        t = np.maximum(0.05, np.random.normal(\n",
    "            loc=tg, scale=sd_t, size=1)) if subjs > 1 else tg\n",
    "        a = np.maximum(0.05, np.random.normal(\n",
    "            loc=ag, scale=sd_a, size=1)) if subjs > 1 else ag\n",
    "        alpha = np.minimum(np.minimum(np.maximum(0.001, np.random.normal(loc=alphag, scale=sd_a, size=1)), alphag+alphag),1) if subjs > 1 else alphag\n",
    "        scaler = np.random.normal(loc=scalerg, scale=sd_v, size=1) if subjs > 1 else scalerg\n",
    "        #create a normalized regressor that is combined with the neural coefficient to create trial-by-trial values for decision threshold\n",
    "        neural_reg = np.random.normal(0,1,size=n)\n",
    "        q_up = np.tile([q_init], n)\n",
    "        q_low = np.tile([q_init], n)\n",
    "        response = np.tile([0.5], n)\n",
    "        feedback = np.tile([0.5], n)\n",
    "        rt = np.tile([0], n)\n",
    "        rew_up = np.random.binomial(1, p_upper, n).astype(float)\n",
    "        rew_low = np.random.binomial(1, p_lower, n).astype(float)\n",
    "        sim_drift = np.tile([0], n)\n",
    "        subj_idx = np.tile([s], n)\n",
    "        d = {'q_up': q_up, 'q_low': q_low, 'sim_drift': sim_drift, 'rew_up': rew_up, 'rew_low': rew_low,\n",
    "             'response': response, 'rt': rt, 'feedback': feedback, 'subj_idx': subj_idx, 'split_by': split_by, 'trial': 1, 'neural_reg': neural_reg}\n",
    "        df = pd.DataFrame(data=d)\n",
    "        df = df[['q_up', 'q_low', 'sim_drift', 'rew_up', 'rew_low',\n",
    "                 'response', 'rt', 'feedback', 'subj_idx', 'split_by', 'trial','neural_reg']]\n",
    "        #generate data trial-by-trial using the Intercept (a), regressor (neural_reg) and coefficient (neural) for decision threshold.\n",
    "        data, params = hddm.generate.gen_rand_data(\n",
    "            {'a': a + neural*df.loc[0, 'neural_reg'], 't': t, 'v': df.loc[0, 'sim_drift'], 'z': z}, subjs=1, size=1)\n",
    "        df.loc[0, 'response'] = data.response[0]\n",
    "        df.loc[0, 'rt'] = data.rt[0]\n",
    "        if (data.response[0] == 1.0):\n",
    "            df.loc[0, 'feedback'] = df.loc[0, 'rew_up']\n",
    "        else:\n",
    "            df.loc[0, 'feedback'] = df.loc[0, 'rew_low']\n",
    "\n",
    "        for i in range(1, n):\n",
    "            df.loc[i, 'trial'] = i + 1\n",
    "            df.loc[i, 'q_up'] = (df.loc[i - 1, 'q_up'] * (1 - df.loc[i - 1, 'response'])) + ((df.loc[i - 1, 'response'])\n",
    "                                                                                             * (df.loc[i - 1, 'q_up'] + (alpha * (df.loc[i - 1, 'rew_up'] - df.loc[i - 1, 'q_up']))))\n",
    "            df.loc[i, 'q_low'] = (df.loc[i - 1, 'q_low'] * (df.loc[i - 1, 'response'])) + ((1 - df.loc[i - 1, 'response'])\n",
    "                                                                                           * (df.loc[i - 1, 'q_low'] + (alpha * (df.loc[i - 1, 'rew_low'] - df.loc[i - 1, 'q_low']))))\n",
    "            df.loc[i, 'sim_drift'] = (df.loc[i, 'q_up'] - df.loc[i, 'q_low']) * (scaler)\n",
    "            data, params = hddm.generate.gen_rand_data(\n",
    "                {'a': a + neural*df.loc[i, 'neural_reg'], 't': t, 'v': df.loc[i, 'sim_drift'] , 'z': z}, subjs=1, size=1)\n",
    "            df.loc[i, 'response'] = data.response[0]\n",
    "            df.loc[i, 'rt'] = data.rt[0]\n",
    "            if (data.response[0] == 1.0):\n",
    "                df.loc[i, 'feedback'] = df.loc[i, 'rew_up']\n",
    "            else:\n",
    "                df.loc[i, 'feedback'] = df.loc[i, 'rew_low']\n",
    "        all_data.append(df)\n",
    "    all_data = pd.concat(all_data, axis=0)\n",
    "    all_data = all_data[['q_up', 'q_low', 'sim_drift', 'response',\n",
    "                         'rt', 'feedback', 'subj_idx', 'split_by', 'trial','neural_reg']]\n",
    "\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create data with function defined above. \n",
    "#This will create trial-by-trial values for decision threshold (a) by adding the coefficient neural (here set to 0.2) \n",
    "#multiplied by a normalized regressor (neural_reg) to the 'Intercept' value of a (here set to 1) \n",
    "data_neural = gen_rand_reg_rlddm_data(a=1,t=0.3,scaler=2,alpha=0.2,neural = 0.2,size=100,p_upper=0.7,p_lower=0.3,subjs=25)\n",
    "data_neural['q_init'] = 0.5\n",
    "data_neural.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run a regressor model estimating the impact of 'neural' on decision threshold a. This should estimate the coefficient a_neural_reg to be 0.2\n",
    "#to run the HDDMrlRegressor you need to include alpha\n",
    "m_reg = hddm.HDDMrlRegressor(data_neural,'a ~ neural_reg',include='alpha')\n",
    "m_reg.sample(1000,burn=250)\n",
    "m_reg.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Regular RL without RT\n",
    "HDDMrl also includes a module to run an RL-model that uses softmax to transform q-values to probability of choosing options associated with upper (response=1) or lower (response=0) boundary. To run this model you type hddm.Hrl instead of hddm.HDDMrl. The setup is the same as for HDDMrl, and for now, the model won't run if you don't include an rt-column. This will be fixed for a future version, but for now, if you don't have RTs you can just create an rt-column where you set all rts to e.g. 0.5. You can choose to estimate separate learning rates for positive and negative learning rate by setting dual=True (see [here](#9.-Separate-learning-rates-for-positive-and-negative-prediction-errors) for more information). The model will by default estimate posterior distributions for the alpha and v parameters. The probability of choosing upper boundary is captured as: <br><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$p_{up} =(e^{-2*z*d_t}-1)/ (e^{-2*d_t}-1)$, <br><br>\n",
    "where ${d_t}=q_{up_t}-q_{low}*v$ and z represents starting point (which for now is fixed to be 0.5). <br>\n",
    "This calculation is equivalent to soft-max transformation when z=0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the model by calling hddm.Hrl (instead of hddm.HDDM for normal model and hddm.HDDMrl for rlddm-model)\n",
    "m_rl = hddm.Hrl(data)\n",
    "#set sample and burn-in\n",
    "m_rl.sample(1500,burn=500,dbname='traces.db',db='pickle')\n",
    "#print stats to get an overview of posterior distribution of estimated parameters\n",
    "m_rl.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter estimates from the pure RL-model are a bit different compared to the RLDDM. This is to be expected as probability of choice in DDM is dependent both on the decsision threshold and the scaled difference in q-values, whereas the RL model only uses the scaled difference in q-values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_rl.plot_posteriors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fig.__ Mixing and autocorrelation looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate convergence\n",
    "models = []\n",
    "for i in range(3):\n",
    "    m = hddm.Hrl(data=data)\n",
    "    m.sample(1500, burn=500,dbname='traces.db',db='pickle')\n",
    "    models.append(m)\n",
    "#get max gelman-statistic value. shouldn't be higher than 1.1\n",
    "np.max(list(gelman_rubin(models).values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convergence looks good, i.e. no parameters with gelman-rubin statistic > 1.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model that has all traces concatenated\n",
    "# of individual models.\n",
    "m_rl = kabuki.utils.concat_models(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha, v = m_rl.nodes_db.node[['alpha','v']]\n",
    "samples = {'alpha':alpha.trace(),'v':v.trace()}\n",
    "samp = pd.DataFrame(data=samples)\n",
    "\n",
    "def corrfunc(x, y, **kws):\n",
    "    r, _ = stats.pearsonr(x, y)\n",
    "    ax = plt.gca()\n",
    "    ax.annotate(\"r = {:.2f}\".format(r),\n",
    "                xy=(.1, .9), xycoords=ax.transAxes)\n",
    "\n",
    "g = sns.PairGrid(samp, palette=[\"red\"])\n",
    "g.map_upper(plt.scatter, s=10)\n",
    "g.map_diag(sns.distplot, kde=False)\n",
    "g.map_lower(sns.kdeplot, cmap=\"Blues_d\")\n",
    "\n",
    "g.map_lower(corrfunc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fig.__ The correlation in the posterior distribution for alpha and v/scaling is somewhat negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior predictive check\n",
    "We can also do posterior predictive check on the RL-model by generating new data with hddm.generate.gen_rand_rl_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty dataframe to store simulated data\n",
    "sim_data = pd.DataFrame()\n",
    "#create a column samp to be used to identify the simulated data sets\n",
    "data['samp'] = 0\n",
    "#load traces\n",
    "traces = m_rl.get_traces()\n",
    "#decide how many times to repeat simulation process. repeating this multiple times is generally recommended as it better captures the uncertainty in the posterior distribution, but will also take some time\n",
    "for i in tqdm(range(1,51)):\n",
    "    #randomly select a row in the traces to use for extracting parameter values\n",
    "    sample = np.random.randint(0,traces.shape[0]-1)\n",
    "    #loop through all subjects in observed data\n",
    "    for s in data.subj_idx.unique():\n",
    "        #get number of trials for each condition.\n",
    "        size0 = len(data[(data['subj_idx']==s) & (data['split_by']==0)].trial.unique())\n",
    "        size1 = len(data[(data['subj_idx']==s) & (data['split_by']==1)].trial.unique())\n",
    "        size2 = len(data[(data['subj_idx']==s) & (data['split_by']==2)].trial.unique())\n",
    "        #set parameter values for simulation\n",
    "        scaler = traces.loc[sample,'v_subj.'+str(s)]\n",
    "        alphaInv = traces.loc[sample,'alpha_subj.'+str(s)]\n",
    "        #take inverse logit of estimated alpha\n",
    "        alpha = np.exp(alphaInv)/(1+np.exp(alphaInv))\n",
    "        #simulate data for each condition changing only values of size, p_upper, p_lower and split_by between conditions.\n",
    "        sim_data0 = hddm.generate.gen_rand_rl_data(scaler=scaler,alpha=alpha,size=size0,p_upper=0.8,p_lower=0.2,split_by=0)\n",
    "        sim_data1 = hddm.generate.gen_rand_rl_data(scaler=scaler,alpha=alpha,size=size1,p_upper=0.7,p_lower=0.3,split_by=1)\n",
    "        sim_data2 = hddm.generate.gen_rand_rl_data(scaler=scaler,alpha=alpha,size=size2,p_upper=0.6,p_lower=0.4,split_by=2)\n",
    "        #append the conditions\n",
    "        sim_data0 = sim_data0.append([sim_data1,sim_data2],ignore_index=True)\n",
    "        #assign subj_idx\n",
    "        sim_data0['subj_idx'] = s\n",
    "        #identify that these are simulated data\n",
    "        sim_data0['type'] = 'simulated'\n",
    "        #identify the simulated data\n",
    "        sim_data0['samp'] = i\n",
    "        #append data from each subject\n",
    "        sim_data = sim_data.append(sim_data0,ignore_index=True)\n",
    "#combine observed and simulated data\n",
    "ppc_rl_data = data[['subj_idx','response','split_by','trial','feedback','samp']].copy()\n",
    "ppc_rl_data['type'] = 'observed'\n",
    "ppc_rl_sdata = sim_data[['subj_idx','response','split_by','trial','feedback','type','samp']].copy()\n",
    "ppc_rl_data = ppc_rl_data.append(ppc_rl_sdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for practical reasons we only look at the first 40 trials for each subject in a given condition\n",
    "plot_ppc_rl_data = ppc_rl_data[ppc_rl_data.trial<41].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bin trials to for smoother estimate of response proportion across learning\n",
    "plot_ppc_rl_data['bin_trial'] = pd.cut(plot_ppc_rl_data.trial,11,labels=np.linspace(0, 10,11)).astype('int64')\n",
    "#calculate means for each sample\n",
    "sums = plot_ppc_rl_data.groupby(['bin_trial','split_by','samp','type']).mean().reset_index()\n",
    "#calculate the overall mean response across samples\n",
    "ppc_rl_sim = sums.groupby(['bin_trial','split_by','type']).mean().reset_index()\n",
    "#initiate columns that will have the upper and lower bound of the hpd\n",
    "ppc_rl_sim['upper_hpd'] = 0\n",
    "ppc_rl_sim['lower_hpd'] = 0\n",
    "for i in range(0,ppc_rl_sim.shape[0]):\n",
    "    #calculate the hpd/hdi of the predicted mean responses across bin_trials\n",
    "    hdi = pymc.utils.hpd(sums.response[(sums['bin_trial']==ppc_rl_sim.bin_trial[i]) & (sums['split_by']==ppc_rl_sim.split_by[i]) & (sums['type']==ppc_rl_sim.type[i])],alpha=0.1)\n",
    "    ppc_rl_sim.loc[i,'upper_hpd'] = hdi[1]\n",
    "    ppc_rl_sim.loc[i,'lower_hpd'] = hdi[0]\n",
    "#calculate error term as the distance from upper bound to mean\n",
    "ppc_rl_sim['up_err'] = ppc_rl_sim['upper_hpd']-ppc_rl_sim['response']\n",
    "ppc_rl_sim['low_err'] = ppc_rl_sim['response']-ppc_rl_sim['lower_hpd']\n",
    "ppc_rl_sim['model'] = 'RL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting evolution of choice proportion for best option across learning for observed and simulated data. Compared for RL and RLDDM models, both with single learnign rate.\n",
    "fig, axs = plt.subplots(figsize=(15, 5),nrows=1, ncols=3, sharex=True,sharey=True)\n",
    "for i in range(0,3):\n",
    "    ax = axs[i]\n",
    "    d_single = ppc_sim[(ppc_sim.split_by==i) & (ppc_sim.type=='simulated')]\n",
    "    #slightly move bin_trial to avoid overlap in errorbars\n",
    "    d_single['bin_trial'] += 0.2\n",
    "    ax.errorbar(d_single.bin_trial, d_single.response, yerr=[d_single.low_err,d_single.up_err], label='simulated_RLDDM',color='orange')\n",
    "    ax = axs[i]\n",
    "    d_rl = ppc_rl_sim[(ppc_rl_sim.split_by==i) & (ppc_rl_sim.type=='simulated')]\n",
    "    ax.errorbar(d_rl.bin_trial, d_rl.response, yerr=[d_rl.low_err,d_rl.up_err], label='simulated_RL',color='green')\n",
    "    ax = axs[i]\n",
    "    d = ppc_sim[(ppc_dual_sim.split_by==i) & (ppc_dual_sim.type=='observed')]\n",
    "    ax.plot(d.bin_trial, d.response,linewidth=3,label='observed')\n",
    "    ax.set_title('split_by = %i' %i,fontsize=20)\n",
    "    ax.set_ylabel('mean response')\n",
    "    ax.set_xlabel('trial')\n",
    "plt.xlim(-0.5,10.5)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fig.__ The predicted choice for the RL-model is very similar to what was predicted in the RLDDM. That is not surprising given that they use the same calculation to get the choice likelihood. The difference between them is instead that the RLDDM could potentially detect the unique contribution of the scaling/drift parameter and the decision threshold onto choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misprediction across learning\n",
    "Another way to visualize this is to look at how the predicted choice misses on the observed across learning, i.e. predicted-observed. As for the other plots we see that the two methods are very similar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rl\n",
    "error_prediction = plot_ppc_rl_data.groupby(['split_by','type','bin_trial'])['response'].mean().reset_index()\n",
    "ep = error_prediction.pivot_table(index=['split_by','bin_trial'],columns='type',values='response').reset_index()\n",
    "ep['diff'] = ep['simulated']-ep['observed']\n",
    "ep['model'] = 'RL'\n",
    "#rlddm\n",
    "error_prediction = plot_ppc_data.groupby(['split_by','type','bin_trial'])['response'].mean().reset_index()\n",
    "ep_rlddm = error_prediction.pivot_table(index=['split_by','bin_trial'],columns='type',values='response').reset_index()\n",
    "ep_rlddm['diff'] = ep_rlddm['simulated']-ep_rlddm['observed']\n",
    "ep_rlddm['model'] = 'RLDDM'\n",
    "#combine\n",
    "ep = ep.append(ep_rlddm)\n",
    "#plot\n",
    "g = sns.relplot(x='bin_trial',y='diff',col='split_by',hue='model',kind='line',ci=False,data=ep,palette=\"Set2_r\")\n",
    "g.map(plt.axhline, y=0, ls=\":\", c=\".5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
